{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmq30AqYzFs6r8qTMb2SDh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/durml91/MMath-Project/blob/duo-branch/Image_Diffusion_(working)/MNIST_diffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLP Mixer"
      ],
      "metadata": {
        "id": "gE72qWJ-wE85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mixer Layer"
      ],
      "metadata": {
        "id": "LA6cjHHLwKFD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we haven't introduced a Gelu in the MLP layer. The basic idea is that we will have divided our image into a bunch of nicely disjoint patches that we flatten (the height and width dimension are flattened into a vector). Think cube! We have flattened the image into a vector but we project each patch into a hidden size that acts as our channels (so no we have a square) and then we have a batch of these images, which in this case is the number of patches (and not the batch of images here) which represents the third dimension of the cube. Ok so per patch, we plug a vector (won't be as long as full image given we flatten each patch and not the full image). So we can say we have S non-overlapping/disjoint image patches per image (think of these as your channels now, so if we were to have rgb channels rather than simply grayscale, then I'm pretty certain the S would be 3 x S - check!). We then proceed to project each patch to a hidden dimension (what we label here as the hidden dimnensions). Lets switch S to P to be. So we have num_patches = P and hidden_size = C. P = num_patches should equal (h x w) / patch_size **2. \n",
        "Now we have our token mixing block then a channel mixing block. So first we take our patches of dim c x p and get the layer norm which is across all c and p (and NOT the batch i.e. just for a single input) and pass them through the token mixer with input P and output P (i.e. it's a map from $\\mathbb{R}^{s} \\to \\mathbb{R}^{s}$. The output will still be of dimension c p so we transpose it to p x c and put it through a second layer norm and then the token mixer. Once it is out, we can simply transpose the array again to recover the identical dimensions with which we started."
      ],
      "metadata": {
        "id": "Qzw1Cto4xApz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MixerBlock(eqx.Module):\n",
        "    patch_mixer: eqx.nn.MLP\n",
        "    hidden_mixer: eqx.nn.MLP\n",
        "    norm1: eqx.nn.LayerNorm\n",
        "    norm2: eqx.nn.LayerNorm\n",
        "\n",
        "    def __init__(\n",
        "        self, num_patches, hidden_size, mix_patch_size, mix_hidden_size, *, key\n",
        "    ):\n",
        "        tkey, ckey = jr.split(key, 2)\n",
        "        self.patch_mixer = eqx.nn.MLP(\n",
        "            num_patches, num_patches, mix_patch_size, depth=1, key=tkey\n",
        "        )\n",
        "        self.hidden_mixer = eqx.nn.MLP(\n",
        "            hidden_size, hidden_size, mix_hidden_size, depth=1, key=ckey\n",
        "        )\n",
        "        self.norm1 = eqx.nn.LayerNorm((hidden_size, num_patches))\n",
        "        self.norm2 = eqx.nn.LayerNorm((num_patches, hidden_size))\n",
        "\n",
        "    def __call__(self, y):\n",
        "        y = y + jax.vmap(self.patch_mixer)(self.norm1(y))\n",
        "        y = einops.rearrange(y, \"c p -> p c\")\n",
        "        y = y + jax.vmap(self.hidden_mixer)(self.norm2(y))\n",
        "        y = einops.rearrange(y, \"p c -> c p\")\n",
        "        return y"
      ],
      "metadata": {
        "id": "VZzdRGOtwF_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Actual network"
      ],
      "metadata": {
        "id": "fncFhNu8wSOr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now for the full mode. Recall hidden_size = C and num_patches = P. Before we start, we get standardise our time relative to the total number of steps of the diffusion process. We then get the shape of our image in order to be able to create an array of t's so that we can concatenate them together along axis 0 which I'm pretty sure is in the channel axis (so in this case I'm pretty sure the number of channels is 2 hence the reason why input_size is + 1 i.e. t acts as anther channel). We first have to get our patches. Our input convolution has spatial_dims set to 2. The in_channel is input_size + 1 (where input_size is the first dim of img_size) and we want the out_channel to have size hidden_size i.e C - makes sense as we will implictly have num_patches by setting the kernel_size and stride. Need to look at in/out channels more. Once we have a patches, we calculate their height and width. Now we can flatten the h x w for each patch and plug into our Mixer Layer to recover dimensionally invariant patches. We can normalise these patches again and the proceed to unflatten each patch. Then finally plug into the upsampler (transpose of the convolution) in order to piece the patches back together."
      ],
      "metadata": {
        "id": "DplHTZdQ1b87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Mixer2d(eqx.Module):\n",
        "    conv_in: eqx.nn.Conv2d\n",
        "    conv_out: eqx.nn.ConvTranspose2d\n",
        "    blocks: list\n",
        "    norm: eqx.nn.LayerNorm\n",
        "    t1: float\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        img_size,\n",
        "        patch_size,\n",
        "        hidden_size,\n",
        "        mix_patch_size,\n",
        "        mix_hidden_size,\n",
        "        num_blocks,\n",
        "        t1,\n",
        "        *,\n",
        "        key,\n",
        "    ):\n",
        "        input_size, height, width = img_size\n",
        "        assert (height % patch_size) == 0\n",
        "        assert (width % patch_size) == 0\n",
        "        num_patches = (height // patch_size) * (width // patch_size)\n",
        "        inkey, outkey, *bkeys = jr.split(key, 2 + num_blocks)\n",
        "\n",
        "        self.conv_in = eqx.nn.Conv2d(\n",
        "            input_size + 1, hidden_size, patch_size, stride=patch_size, key=inkey\n",
        "        )\n",
        "        self.conv_out = eqx.nn.ConvTranspose2d(\n",
        "            hidden_size, input_size, patch_size, stride=patch_size, key=outkey\n",
        "        )\n",
        "        self.blocks = [\n",
        "            MixerBlock(\n",
        "                num_patches, hidden_size, mix_patch_size, mix_hidden_size, key=bkey\n",
        "            )\n",
        "            for bkey in bkeys\n",
        "        ]\n",
        "        self.norm = eqx.nn.LayerNorm((hidden_size, num_patches))\n",
        "        self.t1 = t1\n",
        "\n",
        "    def __call__(self, t, y):\n",
        "        t = t / self.t1\n",
        "        _, height, width = y.shape\n",
        "        t = einops.repeat(t, \"-> 1 h w\", h=height, w=width)\n",
        "        y = jnp.concatenate([y, t])\n",
        "        y = self.conv_in(y)\n",
        "        _, patch_height, patch_width = y.shape\n",
        "        y = einops.rearrange(y, \"c h w -> c (h w)\")\n",
        "        for block in self.blocks:\n",
        "            y = block(y)\n",
        "        y = self.norm(y)\n",
        "        y = einops.rearrange(y, \"c (h w) -> c h w\", h=patch_height, w=patch_width)\n",
        "        return self.conv_out(y)"
      ],
      "metadata": {
        "id": "PaXuek9fwNeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss"
      ],
      "metadata": {
        "id": "wPpcwk_GwcwQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The single loss is per image. It's that weird rearranged loss function (form the DDPMs stuff) and uses the reparamterisation the data to then plug that into the model. We then take the mean as this bit is the expectation/monte carlo estimate over the random gaussian (noise). We also multiplty by some weight function."
      ],
      "metadata": {
        "id": "_j7-F2cC54eY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def single_loss_fn(model, weight, int_beta, data, t, key):\n",
        "    mean = data * jnp.exp(-0.5 * int_beta(t))\n",
        "    var = jnp.maximum(1 - jnp.exp(-int_beta(t)), 1e-5)\n",
        "    std = jnp.sqrt(var)\n",
        "    noise = jr.normal(key, data.shape)\n",
        "    y = mean + std * noise\n",
        "    pred = model(t, y)\n",
        "    return weight(t) * jnp.mean((pred + noise / std) ** 2)"
      ],
      "metadata": {
        "id": "BTa07Q4Dwd6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following is the loss over a batch. Here we don't compute two means (recall there are three means to compute in the loss). This is due to simply being able to calculate an array of uniform value from 0 to t1. We then compute the single loss function over the batch of data and take the mean (this is the monte carlo esimate for the randomly sampled data)."
      ],
      "metadata": {
        "id": "rLgKL0Zw6cal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_loss_fn(model, weight, int_beta, data, t1, key):\n",
        "    batch_size = data.shape[0]\n",
        "    tkey, losskey = jr.split(key)\n",
        "    losskey = jr.split(losskey, batch_size)\n",
        "    # Low-discrepancy sampling over t to reduce variance\n",
        "    t = jr.uniform(tkey, (batch_size,), minval=0, maxval=t1 / batch_size)\n",
        "    t = t + (t1 / batch_size) * jnp.arange(batch_size)\n",
        "    loss_fn = ft.partial(single_loss_fn, model, weight, int_beta)\n",
        "    loss_fn = jax.vmap(loss_fn)\n",
        "    return jnp.mean(loss_fn(data, t, losskey))"
      ],
      "metadata": {
        "id": "w4VFmz09wfhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Update step"
      ],
      "metadata": {
        "id": "PpIQvqKaw2ov"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall that equinox works slightly differently to flax in that the pytrees structure doesn't require you to separate the parameters from the model. Here we work out the value/loss and grad. Basically loss_fn computes the average loss, spits this out, and backpropogates the error through the network to the grads of the loss w.r.t. to the weights and biases. We then call opt_update on the grads; here opt_state is the optimiser (e.g. sgd or adam). So we give opt_update the grads and the optimiser and is gives back the optimiser and the updated weights which we then apply to the model. We then return another key (not sure why?)"
      ],
      "metadata": {
        "id": "K47eTjyi7IHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_step(model, weight, int_beta, data, t1, key, opt_state, opt_update):\n",
        "    loss_fn = eqx.filter_value_and_grad(batch_loss_fn)\n",
        "    loss, grads = loss_fn(model, weight, int_beta, data, t1, key)\n",
        "    updates, opt_state = opt_update(grads, opt_state)\n",
        "    model = eqx.apply_updates(model, updates)\n",
        "    key = jr.split(key, 1)[0]\n",
        "    return loss, model, key, opt_state"
      ],
      "metadata": {
        "id": "NTxsw4I6w2BL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ODE solver"
      ],
      "metadata": {
        "id": "yuNpGCNrwhPg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the ODE solver using the diffrax package. We define the drift term - weird function but it basically spits out a vector of int_beta applied to t in the right dimension i.e. it's the vector of time and we apply beta_t to each one. We use the Tsit5() solver. We sample from a standard Gaussian in the right dimnesions and then sample backwards from t1 to t0, using the discretised timesteps dt0 (but negative given we are going the other direction)"
      ],
      "metadata": {
        "id": "_o99LvJ88bBL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the SDE sampler doesn't work this is precisely why. t comes into that function as a vector as it is the entire discretisation step applied at once. If you want beta_t to be multi dim, you need increase the dimension of beta in another direction i.e. 28 in new dimnesion on top of the new beta (so it's actually just a matrix, with the timesteps in one dim and just repeated values of that specific timestep in another as we need it running in the right dimension)."
      ],
      "metadata": {
        "id": "HiqxkSyi87x-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def single_sample_fn(model, int_beta, data_shape, dt0, t1, key):\n",
        "    def drift(t, y, args):\n",
        "        _, beta = jax.jvp(int_beta, (t,), (jnp.ones_like(t),))\n",
        "        return -0.5 * beta * (y + model(t, y))\n",
        "\n",
        "    term = dfx.ODETerm(drift)\n",
        "    solver = dfx.Tsit5()\n",
        "    t0 = 0\n",
        "    y1 = jr.normal(key, data_shape)\n",
        "    # reverse time, solve from t1 to t0\n",
        "    sol = dfx.diffeqsolve(term, solver, t1, t0, -dt0, y1, adjoint=dfx.NoAdjoint())\n",
        "    return sol.ys[0]"
      ],
      "metadata": {
        "id": "-yXPGknLwi4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data import"
      ],
      "metadata": {
        "id": "2ckIbvBGwlGS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nothing much to say except we specify the data dimension here."
      ],
      "metadata": {
        "id": "aqkoB4bZ90NP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mnist():\n",
        "    filename = \"train-images-idx3-ubyte.gz\"\n",
        "    url_dir = \"https://storage.googleapis.com/cvdf-datasets/mnist\"\n",
        "    target_dir = os.getcwd() + \"/data/mnist\"\n",
        "    url = f\"{url_dir}/{filename}\"\n",
        "    target = f\"{target_dir}/{filename}\"\n",
        "\n",
        "    if not os.path.exists(target):\n",
        "        os.makedirs(target_dir, exist_ok=True)\n",
        "        urllib.request.urlretrieve(url, target)\n",
        "        print(f\"Downloaded {url} to {target}\")\n",
        "\n",
        "    with gzip.open(target, \"rb\") as fh:\n",
        "        _, batch, rows, cols = struct.unpack(\">IIII\", fh.read(16))\n",
        "        shape = (batch, 1, rows, cols)\n",
        "        return jnp.array(array.array(\"B\", fh.read()), dtype=jnp.uint8).reshape(shape)"
      ],
      "metadata": {
        "id": "y9NMT4xPwmmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data batch randomiser"
      ],
      "metadata": {
        "id": "TKeLs9w_wnFy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data loader shuffles the data into randomly permuted batches. We get the indices of the dataset, permute them and extract a randomy batch form the random array of indices (number same as batch_size). Yield is this weird generator (vs iterator) function but basically think of it as return. However, here we can now set the end to where we left off and aim to end at the next batch. All pretty simple (just remember the code only passes through the first while column once whilst it keeps iterating over the nested while loop until finished)."
      ],
      "metadata": {
        "id": "FZOP7iZj95pL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dataloader(data, batch_size, *, key):\n",
        "    dataset_size = data.shape[0]\n",
        "    indices = jnp.arange(dataset_size)\n",
        "    while True:\n",
        "        perm = jr.permutation(key, indices)\n",
        "        (key,) = jr.split(key, 1)\n",
        "        start = 0\n",
        "        end = batch_size\n",
        "        while end < dataset_size:\n",
        "            batch_perm = perm[start:end]\n",
        "            yield data[batch_perm]\n",
        "            start = end\n",
        "            end = start + batch_size"
      ],
      "metadata": {
        "id": "MoLlODHSwrGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main function"
      ],
      "metadata": {
        "id": "UwFWy1bsw9NI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we input all of the parameters and hyperparameters that we need. We load the data but we also remember to standardise the data (so the value are in $[0,1]$). We initiate the model and optimisers. We also define the weight function and the beta_t function. We then train the model for the number of epochs specified. We then sample the data. We then \"de-standardise\" it. We then clip it (which means ensure all the data is in between the max and min values specified"
      ],
      "metadata": {
        "id": "Ua2CVdQl-zyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(\n",
        "    # Model hyperparameters\n",
        "    patch_size=4,\n",
        "    hidden_size=64,\n",
        "    mix_patch_size=512,\n",
        "    mix_hidden_size=512,\n",
        "    num_blocks=4,\n",
        "    t1=10.0,\n",
        "    # Optimisation hyperparameters\n",
        "    num_steps=1_000_000,\n",
        "    lr=3e-4,\n",
        "    batch_size=256,\n",
        "    print_every=10_000,\n",
        "    # Sampling hyperparameters\n",
        "    dt0=0.1,\n",
        "    sample_size=10,\n",
        "    # Seed\n",
        "    seed=5678,\n",
        "):\n",
        "    key = jr.PRNGKey(seed)\n",
        "    model_key, train_key, loader_key, sample_key = jr.split(key, 4)\n",
        "    data = mnist()\n",
        "    data_mean = jnp.mean(data)\n",
        "    data_std = jnp.std(data)\n",
        "    data_max = jnp.max(data)\n",
        "    data_min = jnp.min(data)\n",
        "    data_shape = data.shape[1:]\n",
        "    data = (data - data_mean) / data_std\n",
        "\n",
        "    model = Mixer2d(\n",
        "        data_shape,\n",
        "        patch_size,\n",
        "        hidden_size,\n",
        "        mix_patch_size,\n",
        "        mix_hidden_size,\n",
        "        num_blocks,\n",
        "        t1,\n",
        "        key=model_key,\n",
        "    )\n",
        "    int_beta = lambda t: t  # Try experimenting with other options here!\n",
        "    weight = lambda t: 1 - jnp.exp(\n",
        "        -int_beta(t)\n",
        "    )  # Just chosen to upweight the region near t=0.\n",
        "\n",
        "    opt = optax.adabelief(lr)\n",
        "    # Optax will update the floating-point JAX arrays in the model.\n",
        "    opt_state = opt.init(eqx.filter(model, eqx.is_inexact_array))\n",
        "\n",
        "    total_value = 0\n",
        "    total_size = 0\n",
        "    for step, data in zip(\n",
        "        range(num_steps), dataloader(data, batch_size, key=loader_key)\n",
        "    ):\n",
        "        value, model, train_key, opt_state = make_step(\n",
        "            model, weight, int_beta, data, t1, train_key, opt_state, opt.update\n",
        "        )\n",
        "        total_value += value.item()\n",
        "        total_size += 1\n",
        "        if (step % print_every) == 0 or step == num_steps - 1:\n",
        "            print(f\"Step={step} Loss={total_value / total_size}\")\n",
        "            total_value = 0\n",
        "            total_size = 0\n",
        "\n",
        "    sample_key = jr.split(sample_key, sample_size**2)\n",
        "    sample_fn = ft.partial(single_sample_fn, model, int_beta, data_shape, dt0, t1)\n",
        "    sample = jax.vmap(sample_fn)(sample_key)\n",
        "    sample = data_mean + data_std * sample\n",
        "    sample = jnp.clip(sample, data_min, data_max)\n",
        "    sample = einops.rearrange(\n",
        "        sample, \"(n1 n2) 1 h w -> (n1 h) (n2 w)\", n1=sample_size, n2=sample_size\n",
        "    )\n",
        "    plt.imshow(sample, cmap=\"Greys\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "QBHtR5GBw8Zi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}