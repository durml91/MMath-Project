{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vkxG8UA55CDs",
        "boKbD65w2odj",
        "XYdPvNIg2q6C",
        "aH_B8CT82uLR",
        "YuPSPusZ2v3N",
        "5C5kiQ_k2x7F",
        "udhjg0J-9pK0",
        "gV_U-JJrL-jC",
        "7wfr3bbCSZkk"
      ],
      "authorship_tag": "ABX9TyMK2LX3U9KJ5+PxGPGh48QO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/durml91/MMath-Project/blob/duo-branch/Image_Diffusion_(working)/DiT%20Diffusion/DiT-V3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**DiT implementation**"
      ],
      "metadata": {
        "id": "YJW-hYHrRghA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports and Installs"
      ],
      "metadata": {
        "id": "CwbREoSGRkg-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Need to install new version of Jax for package compatibility"
      ],
      "metadata": {
        "id": "9JBPitYdRoFm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TB7c1s9yAoVp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b72ed57-2b28-448a-bfbd-675d941468dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
            "Collecting jaxlib==0.4.2+cuda11.cudnn82\n",
            "  Downloading https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.4.2%2Bcuda11.cudnn82-cp38-cp38-manylinux2014_x86_64.whl (164.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.4/164.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from jaxlib==0.4.2+cuda11.cudnn82) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.8/dist-packages (from jaxlib==0.4.2+cuda11.cudnn82) (1.7.3)\n",
            "Installing collected packages: jaxlib\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.4.4+cuda11.cudnn82\n",
            "    Uninstalling jaxlib-0.4.4+cuda11.cudnn82:\n",
            "      Successfully uninstalled jaxlib-0.4.4+cuda11.cudnn82\n",
            "Successfully installed jaxlib-0.4.2+cuda11.cudnn82\n"
          ]
        }
      ],
      "source": [
        "!pip install jaxlib==0.4.2+cuda11.cudnn82 -f  https://storage.googleapis.com/jax-releases/jax_cuda_releases.html # [cuda]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade jax[cpu]"
      ],
      "metadata": {
        "id": "xWmJRGh6nBIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install packages"
      ],
      "metadata": {
        "id": "53kc_s37RsQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffrax\n",
        "!pip install equinox\n",
        "!pip install einops\n",
        "!pip install optax"
      ],
      "metadata": {
        "id": "ZAhw7yT6AvfB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c9c1044-7c09-453d-b4c3-33599e2cebfe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting diffrax\n",
            "  Downloading diffrax-0.3.1-py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.4/140.4 KB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting equinox>=0.10.0\n",
            "  Downloading equinox-0.10.1-py3-none-any.whl (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.7/108.7 KB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jax>=0.4.3 in /usr/local/lib/python3.8/dist-packages (from diffrax) (0.4.4)\n",
            "Collecting jaxtyping>=0.2.12\n",
            "  Downloading jaxtyping-0.2.13-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.8/dist-packages (from jax>=0.4.3->diffrax) (1.7.3)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.8/dist-packages (from jax>=0.4.3->diffrax) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from jax>=0.4.3->diffrax) (1.22.4)\n",
            "Collecting typeguard>=2.13.3\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.8/dist-packages (from jaxtyping>=0.2.12->equinox>=0.10.0->diffrax) (4.5.0)\n",
            "Installing collected packages: typeguard, jaxtyping, equinox, diffrax\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 2.7.1\n",
            "    Uninstalling typeguard-2.7.1:\n",
            "      Successfully uninstalled typeguard-2.7.1\n",
            "Successfully installed diffrax-0.3.1 equinox-0.10.1 jaxtyping-0.2.13 typeguard-2.13.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: equinox in /usr/local/lib/python3.8/dist-packages (0.10.1)\n",
            "Requirement already satisfied: jaxtyping>=0.2.12 in /usr/local/lib/python3.8/dist-packages (from equinox) (0.2.13)\n",
            "Requirement already satisfied: jax>=0.4.3 in /usr/local/lib/python3.8/dist-packages (from equinox) (0.4.4)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.8/dist-packages (from jax>=0.4.3->equinox) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from jax>=0.4.3->equinox) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.8/dist-packages (from jax>=0.4.3->equinox) (1.7.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.8/dist-packages (from jaxtyping>=0.2.12->equinox) (4.5.0)\n",
            "Requirement already satisfied: typeguard>=2.13.3 in /usr/local/lib/python3.8/dist-packages (from jaxtyping>=0.2.12->equinox) (2.13.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optax\n",
            "  Downloading optax-0.1.4-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.9/154.9 KB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.8/dist-packages (from optax) (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from optax) (1.22.4)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.8/dist-packages (from optax) (0.4.2+cuda11.cudnn82)\n",
            "Collecting chex>=0.1.5\n",
            "  Downloading chex-0.1.6-py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.9/87.9 KB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from optax) (1.4.0)\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.8/dist-packages (from optax) (0.4.4)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.8/dist-packages (from chex>=0.1.5->optax) (0.1.8)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from chex>=0.1.5->optax) (0.12.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.8/dist-packages (from jax>=0.1.55->optax) (1.7.3)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.8/dist-packages (from jax>=0.1.55->optax) (3.3.0)\n",
            "Installing collected packages: chex, optax\n",
            "Successfully installed chex-0.1.6 optax-0.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "DGZx1OUJRuUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import array\n",
        "import functools as ft\n",
        "import gzip\n",
        "import os\n",
        "import struct\n",
        "import urllib.request\n",
        "\n",
        "import diffrax as dfx  # https://github.com/patrick-kidger/diffrax\n",
        "import einops  # https://github.com/arogozhnikov/einops\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.random as jr\n",
        "import matplotlib.pyplot as plt\n",
        "import optax  # https://github.com/deepmind/optax\n",
        "\n",
        "import equinox as eqx"
      ],
      "metadata": {
        "id": "E1AYxrBfAxC6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate rng key**"
      ],
      "metadata": {
        "id": "1Bw9Y9YTRwKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "key = jr.PRNGKey(2023)"
      ],
      "metadata": {
        "id": "7CDF6Fp0CL4J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup for saving model parameters - only run once!"
      ],
      "metadata": {
        "id": "o-FpEm9rR4Iv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFbT8W33BUPS",
        "outputId": "5aadb028-5bc9-4ca4-d013-b0278bea71e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data loader and data shuffler"
      ],
      "metadata": {
        "id": "RiTiRLb7XjXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mnist():\n",
        "    filename = \"train-images-idx3-ubyte.gz\"\n",
        "    url_dir = \"https://storage.googleapis.com/cvdf-datasets/mnist\"\n",
        "    target_dir = os.getcwd() + \"/data/mnist\"\n",
        "    url = f\"{url_dir}/{filename}\"\n",
        "    target = f\"{target_dir}/{filename}\"\n",
        "\n",
        "    if not os.path.exists(target):\n",
        "        os.makedirs(target_dir, exist_ok=True)\n",
        "        urllib.request.urlretrieve(url, target)\n",
        "        print(f\"Downloaded {url} to {target}\")\n",
        "\n",
        "    with gzip.open(target, \"rb\") as fh:\n",
        "        _, batch, rows, cols = struct.unpack(\">IIII\", fh.read(16))\n",
        "        shape = (batch, 1, rows, cols)\n",
        "        return jnp.array(array.array(\"B\", fh.read()), dtype=jnp.uint8).reshape(shape)\n",
        "\n",
        "def cifar():\n",
        "  from tensorflow.keras.datasets import cifar10\n",
        "  (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "  set1 = jnp.array(x_train)\n",
        "  set2 = jnp.array(x_test)\n",
        "\n",
        "  data = jnp.concatenate((set1, set2))\n",
        "\n",
        "  data_reag = einops.rearrange(data, \"n h w c -> n c h w\")\n",
        "  return data_reag\n",
        "\n",
        "\n",
        "def dataloader(data, batch_size, *, key):\n",
        "    dataset_size = data.shape[0]\n",
        "    indices = jnp.arange(dataset_size)\n",
        "    while True:\n",
        "        perm = jr.permutation(key, indices)\n",
        "        (key,) = jr.split(key, 1)\n",
        "        start = 0\n",
        "        end = batch_size\n",
        "        while end < dataset_size:\n",
        "            batch_perm = perm[start:end]\n",
        "            yield data[batch_perm]\n",
        "            start = end\n",
        "            end = start + batch_size"
      ],
      "metadata": {
        "id": "Rgx0ctSJXlT5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DiT Model"
      ],
      "metadata": {
        "id": "MxSYycHl2mpq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Utility functions**"
      ],
      "metadata": {
        "id": "toAYtcuUWfh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@eqx.filter_jit\n",
        "def modulate(x, shift, scale):\n",
        "    scale = jnp.expand_dims(scale, axis=0) \n",
        "    shift = jnp.expand_dims(shift, axis=0)  \n",
        "    c = (1 + scale) + shift\n",
        "    return x * c"
      ],
      "metadata": {
        "id": "UrDibia_WiyI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@eqx.filter_jit\n",
        "def get_2d_sincos_pos_embed(n_embd, grid_size):\n",
        "\n",
        "    grid_h = jnp.arange(grid_size, dtype=float)\n",
        "    grid_w = jnp.arange(grid_size, dtype=float)\n",
        "    grid = jnp.meshgrid(grid_w, grid_h)\n",
        "    grid = jnp.stack(grid, axis=0)\n",
        "\n",
        "    #grid = einops.rearrange(grid, \" 2 d f -> 2 1 d f\")\n",
        "    grid = jnp.reshape(grid, (2, 1, grid_size, grid_size))\n",
        "    pos_embed = get_2d_sincos_pos_embed_from_grid(n_embd, grid)\n",
        "    return pos_embed\n",
        "\n",
        "\n",
        "##################################################################################\n",
        "\n",
        "@eqx.filter_jit\n",
        "def get_2d_sincos_pos_embed_from_grid(n_embd, grid):\n",
        "    assert n_embd % 2 == 0\n",
        "\n",
        "\n",
        "    emb_h = get_1d_sincos_pos_embed_from_grid(n_embd // 2, grid[0]) # (H*W, D/2)\n",
        "    emb_w = get_1d_sincos_pos_embed_from_grid(n_embd // 2, grid[1]) # (H*W, D/2)\n",
        "\n",
        "    emb = jnp.concatenate([emb_h, emb_w], axis=1)  #(H*W, D)\n",
        "    return emb\n",
        "\n",
        "\n",
        "##################################################################################\n",
        "\n",
        "@eqx.filter_jit\n",
        "def get_1d_sincos_pos_embed_from_grid(n_embd, pos):\n",
        "    assert n_embd % 2 == 0\n",
        "    omega = jnp.arange(n_embd // 2, dtype=float)\n",
        "    omega /= n_embd / 2\n",
        "    omega = 1. / 10000*omega #(D/2)\n",
        "\n",
        "    pos = jnp.array(pos)\n",
        "    #print(pos.shape)\n",
        "    #pos = einops.rearrange(pos, \"a -> a 0\")\n",
        "    out = jnp.outer(pos, omega)\n",
        "\n",
        "    emb_sin = jnp.sin(out)\n",
        "    emb_cos = jnp.cos(out)\n",
        "\n",
        "    emb = jnp.concatenate([emb_sin, emb_cos], axis=1)\n",
        "    return emb"
      ],
      "metadata": {
        "id": "EkoixIOpWs0g"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NN modules**"
      ],
      "metadata": {
        "id": "gnBO4_x7WcSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#############################################\n",
        "##############                ###############\n",
        "##############    DiT model   ###############\n",
        "##############                ###############\n",
        "#############################################\n",
        "\n",
        "\"\"\"Diffusion models meet Transformers!\"\"\"\n",
        "\n",
        "\n",
        "###########   Time embedding    #############\n",
        "\n",
        "\n",
        "\n",
        "###### Define silu activation ######\n",
        "\n",
        "from typing import Callable\n",
        "\n",
        "class Lambda1(eqx.Module):\n",
        "    fn: Callable\n",
        "    \n",
        "    def __call__(self, x, *, key=None):\n",
        "        return self.fn(x)\n",
        "\n",
        "###### Time embedding ######\n",
        "\n",
        "class TimeStepEmbedder(eqx.Module):\n",
        "    mlp: eqx.nn.Sequential\n",
        "    frequency_embedding_size: int\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_size,\n",
        "        frequency_embedding_size,   #set as 256\n",
        "        key\n",
        "    ):\n",
        "        l1key, l2key = jr.split(key, 2)\n",
        "        self.mlp = eqx.nn.Sequential([\n",
        "            eqx.nn.Linear(frequency_embedding_size, hidden_size, key=l1key),\n",
        "            Lambda1(jax.nn.silu),\n",
        "            eqx.nn.Linear(hidden_size, hidden_size, key=l2key)\n",
        "        ])\n",
        "        self.frequency_embedding_size = frequency_embedding_size\n",
        "\n",
        "    def __call__(self, t, max_period=10000):\n",
        "        dim = self.frequency_embedding_size\n",
        "        half = dim // 2\n",
        "        freqs = jnp.exp(\n",
        "            -jnp.log(max_period) * jnp.arange(0, half, dtype=float) / half\n",
        "        )\n",
        "        args = t[:, None].astype(float) * freqs[None]\n",
        "        embedding = jnp.concatenate([jnp.cos(args), jnp.sin(args)], axis=-1)\n",
        "        if dim % 2:\n",
        "            embedding = jnp.concatenate([embedding, jnp.zeros_like(embedding[:, :1])], axis=-1)\n",
        "        t_freq = embedding\n",
        "        t_emb = jax.vmap(self.mlp)(t_freq)\n",
        "        return t_emb\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##########   Multi-Head Attention   #########\n",
        "\n",
        "\n",
        "class MultiAtt(eqx.Module):\n",
        "    n_embed: int\n",
        "    n_head: int\n",
        "    mha: eqx.nn.MultiheadAttention\n",
        "\n",
        "    def __init__(self, n_embed, n_head, key):\n",
        "        self.n_embed = n_embed\n",
        "        self.n_head = n_head\n",
        "        assert self.n_embed % self.n_head ==0\n",
        "        atkey, prkey, mhakey = jr.split(key, 3)\n",
        "        self.mha = eqx.nn.MultiheadAttention(num_heads=self.n_head,\n",
        "                                             query_size = self.n_embed,\n",
        "                                             key_size=self.n_embed,\n",
        "                                             value_size=self.n_embed,\n",
        "                                             output_size=self.n_embed,\n",
        "                                             use_query_bias=True,\n",
        "                                             use_key_bias=True,\n",
        "                                             use_value_bias=True,\n",
        "                                             use_output_bias=True,\n",
        "                                             key=mhakey)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        values = jax.vmap(self.mha)(x, x, x)\n",
        "        return values\n",
        "\n",
        "\n",
        "##############    DiT Block     ##############\n",
        "\n",
        "\n",
        "class DitBlock(eqx.Module):\n",
        "    norm1: eqx.nn.LayerNorm\n",
        "    norm2: eqx.nn.LayerNorm\n",
        "    attn: eqx.Module\n",
        "    Mlp: eqx.nn.MLP\n",
        "    adaLN_modulation: eqx.nn.Sequential\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_size,\n",
        "        n_head,\n",
        "        mlp_ratio,   # = 4.0\n",
        "        key,\n",
        "    ):\n",
        "        mkey, adakey = jr.split(key, 2)\n",
        "        self.norm1 = eqx.nn.LayerNorm(hidden_size, eps = 1e-06, elementwise_affine=False)\n",
        "        self.attn = MultiAtt(hidden_size, n_head=n_head, key=key)\n",
        "        self.norm2 = eqx.nn.LayerNorm(hidden_size, eps = 1e-06, elementwise_affine=False)\n",
        "        mlp_hidden_size = int(hidden_size * mlp_ratio)\n",
        "        self.Mlp = eqx.nn.MLP(hidden_size, hidden_size, mlp_hidden_size, 1, key=mkey)\n",
        "        self.adaLN_modulation = eqx.nn.Sequential([\n",
        "            Lambda1(jax.nn.silu),\n",
        "            eqx.nn.Linear(hidden_size, 6 * hidden_size, key=adakey)\n",
        "        ])\n",
        "\n",
        "    def __call__(self, x, c):\n",
        "        temp = jax.vmap(self.adaLN_modulation)(c)\n",
        "        shift_msa, scale_msa, gate_msa, shift_mlp, scale_mlp, gate_mlp = jnp.array_split(temp, 6, axis=1)\n",
        "        gate_msa = jnp.expand_dims(gate_msa, axis=0)\n",
        "        a = jax.vmap(self.norm1)(x)\n",
        "        tem = modulate(a, shift_msa, scale_msa)\n",
        "        x = x + gate_msa * self.attn(tem)\n",
        "        gate_mlp = jnp.expand_dims(gate_mlp, axis=0)\n",
        "        b = jax.vmap(self.norm2)(x)\n",
        "        tems = modulate(self.norm2(x), shift_mlp, scale_mlp)     \n",
        "        x = x + gate_mlp * jax.vmap(jax.vmap(self.Mlp))(tems)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#################   Final Layer   ################\n",
        "\n",
        "\n",
        "\n",
        "class FinalLayer(eqx.Module):\n",
        "    norm_final: eqx.nn.LayerNorm\n",
        "    linear: eqx.nn.Linear\n",
        "    adaLN_modulation: eqx.nn.Linear\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_size,\n",
        "        patch_size,\n",
        "        out_channels,\n",
        "        key\n",
        "    ):\n",
        "        lkey, adakey = jr.split(key, 2)\n",
        "        self.norm_final = eqx.nn.LayerNorm(hidden_size, eps=1e-6, elementwise_affine=False)\n",
        "        self.linear = eqx.nn.Linear(hidden_size, patch_size * patch_size * out_channels, key=lkey)\n",
        "        self.adaLN_modulation = eqx.nn.Linear(hidden_size, 2 * hidden_size, key=adakey)\n",
        "\n",
        "\n",
        "    def __call__(self, x, c):\n",
        "        c = jax.nn.silu(c)\n",
        "        temp = jax.vmap(self.adaLN_modulation)(c)\n",
        "        shift, scale = jnp.array_split(temp, 2, axis=1)\n",
        "        x = modulate(self.norm_final(x), shift, scale)\n",
        "        x = jax.vmap(jax.vmap(self.linear))(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "###########   Patch embedding   ##############\n",
        "\n",
        "class PatchEmbed(eqx.Module):\n",
        "    num_patches:int\n",
        "    proj: eqx.nn.Conv2d\n",
        "    patch_size: int\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        img_size,\n",
        "        patch_size,\n",
        "        in_chans,\n",
        "        n_embd,\n",
        "        key\n",
        "    ):\n",
        "        patkey, _ = jr.split(key,2)\n",
        "        self.patch_size = patch_size\n",
        "        dg = img_size // self.patch_size\n",
        "        self.num_patches = dg ** 2\n",
        "        self.proj = eqx.nn.Conv2d(in_chans, n_embd, self.patch_size, self.patch_size, key=patkey)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        x = jnp.array(x, dtype=float)\n",
        "        x = jax.vmap(self.proj)(x)\n",
        "        x = einops.rearrange(x, \"B C H W -> B (H W) C\")\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "###########   Parameter module    ##########\n",
        "\n",
        "class Params(eqx.Module):\n",
        "    param: jnp.ndarray\n",
        "\n",
        "    def __init__(self, num_patches, hidden_size):\n",
        "        self.param = jnp.zeros((1, num_patches, hidden_size), dtype = float)\n",
        "\n",
        "    def __call__(self):\n",
        "        return self.param\n",
        "\n",
        "\n",
        "##########    DiT   ##########\n",
        "\n",
        "\n",
        "class DiT(eqx.Module):\n",
        "    in_channels: int\n",
        "    out_channels: int\n",
        "    patch_size: int\n",
        "    n_head: int\n",
        "\n",
        "    x_embedder: eqx.Module\n",
        "    t_embedder: eqx.Module\n",
        "    pos_embed: eqx.Module\n",
        "    blocks: list\n",
        "    final_layer: eqx.Module\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size=28,\n",
        "        patch_size=4,\n",
        "        in_channels=1,\n",
        "        hidden_size=384,\n",
        "        depth=4,  \n",
        "        n_head=6,  \n",
        "        mlp_ratio=4.0,  #fixed\n",
        "        frequency_embedding_size=256,   #fixed\n",
        "        *,\n",
        "        key=key,\n",
        "        \n",
        "    ):\n",
        "        xkey, tkey, flkey, *dbkeys = jr.split(key, 3 + depth)\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = in_channels\n",
        "        self.patch_size = patch_size\n",
        "        self.n_head = n_head\n",
        "        self.x_embedder = PatchEmbed(input_size, patch_size, in_channels, hidden_size, key=xkey)\n",
        "        self.t_embedder = TimeStepEmbedder(hidden_size, frequency_embedding_size, key=tkey)\n",
        "        num_patches = self.x_embedder.num_patches\n",
        "        self.pos_embed = Params(num_patches, hidden_size)\n",
        "        self.blocks = [\n",
        "            DitBlock(\n",
        "                hidden_size, n_head, mlp_ratio, key = key\n",
        "            )\n",
        "            for dbkey in dbkeys                                   #_ in range(depth)           #*bkeys = jr.split(key, num_blocks)\n",
        "        ]\n",
        "        self.final_layer = FinalLayer(hidden_size, patch_size, self.out_channels, key=flkey)\n",
        "\n",
        "        pos_embed = get_2d_sincos_pos_embed(self.pos_embed().shape[-1], int(self.x_embedder.num_patches ** 0.5))\n",
        "        pos_embed = jnp.array(pos_embed, dtype=float)\n",
        "        #pos_embed = pos_embed.copy()      ##########new line - shouldn't make a difference! but tried just in case - shouldn't have adverse effect either, so just a free try really!##########\n",
        "        self.pos_embed = jnp.expand_dims(pos_embed, axis=0)\n",
        "        \n",
        "    \n",
        "    def unpatchify(self, x):\n",
        "        \"\"\"\n",
        "        x: (N, T, patch_size ** 2 * C)\n",
        "        imgs: (N, H, W, C)\n",
        "        \"\"\"\n",
        "        c = self.out_channels      \n",
        "        p = self.x_embedder.patch_size \n",
        "        h = w = int(x.shape[1] ** 0.5)    \n",
        "        x = jnp.reshape(x, (x.shape[0], h, w, p, p, c))\n",
        "        x = einops.rearrange(x, \"n h w p q c->n c h p w q\")\n",
        "        imgs = jnp.reshape(x, (x.shape[0], c, h * p, h * p))\n",
        "        return imgs\n",
        "    \n",
        "    def __call__(self, x, t):\n",
        "        #pos_embed = get_2d_sincos_pos_embed(self.pos_embed().shape[-1], int(self.x_embedder.num_patches ** 0.5))\n",
        "        \n",
        "        \n",
        "        \"\"\"\n",
        "        x: (N, C, H, W)\n",
        "        t: (N, )\n",
        "        \"\"\"\n",
        "        t = jnp.array([t], dtype=int)\n",
        "        x = self.x_embedder(x) + self.pos_embed  # (N, T, D), where T = H * W / patch_size ** 2\n",
        "        t = self.t_embedder(t)   # (N, D)\n",
        "        for block in self.blocks:\n",
        "            x = block(x,t)    # (N, T, D)\n",
        "        x = self.final_layer(x, t)     # (N, T, patch_size ** 2 * out_channels) - N is the batch_size, T is the number of patches, \n",
        "        x = self.unpatchify(x)        # (N, out_channels, H, W)\n",
        "        x = jnp.squeeze(x, axis=0)\n",
        "        return x"
      ],
      "metadata": {
        "id": "rLBy2RgjSNc_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss functions"
      ],
      "metadata": {
        "id": "rDm2oF452jQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def single_loss_fn(model, weight, int_beta, data, t, key):\n",
        "    mean = data * jnp.exp(-0.5 * int_beta(t))\n",
        "    var = jnp.maximum(1 - jnp.exp(-int_beta(t)), 1e-5)\n",
        "    std = jnp.sqrt(var)\n",
        "    noise = jr.normal(key, data.shape)\n",
        "    y = mean + std * noise\n",
        "    y = jnp.expand_dims(y, axis=0)\n",
        "    pred = model(y,t)\n",
        "    return weight(t) * jnp.mean((pred + noise / std) ** 2)\n",
        "\n",
        "\n",
        "def batch_loss_fn(model, weight, int_beta, data, t1, key):\n",
        "    batch_size = data.shape[0]\n",
        "    tkey, losskey = jr.split(key)\n",
        "    losskey = jr.split(losskey, batch_size)\n",
        "    # Low-discrepancy sampling over t to reduce variance\n",
        "    t = jr.uniform(tkey, (batch_size,), minval=0, maxval=t1 / batch_size)\n",
        "    t = t + (t1 / batch_size) * jnp.arange(batch_size)\n",
        "    loss_fn = ft.partial(single_loss_fn, model, weight, int_beta)\n",
        "    loss_fn = jax.vmap(loss_fn)\n",
        "    return jnp.mean(loss_fn(data, t, losskey))"
      ],
      "metadata": {
        "id": "Xf-iL2jpBEB2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Update function"
      ],
      "metadata": {
        "id": "kUh2huWlXtxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@eqx.filter_jit\n",
        "def make_step(model, weight, int_beta, data, t1, key, opt_state, opt_update):\n",
        "    loss_fn = eqx.filter_value_and_grad(batch_loss_fn)\n",
        "    loss, grads = loss_fn(model, weight, int_beta, data, t1, key)\n",
        "    updates, opt_state = opt_update(grads, opt_state)\n",
        "    model = eqx.apply_updates(model, updates)\n",
        "    key = jr.split(key, 1)[0]\n",
        "    return loss, model, key, opt_state"
      ],
      "metadata": {
        "id": "J0sVh0_nBKOZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sampler"
      ],
      "metadata": {
        "id": "RRsIwypJjORC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@eqx.filter_jit\n",
        "def single_sample_fn(model, int_beta, data_shape, dt0, t1, key):\n",
        "    def drift(t, y, args):\n",
        "        _, beta = jax.jvp(int_beta, (t,), (jnp.ones_like(t),))\n",
        "        y = jnp.expand_dims(y, axis=0)\n",
        "        c = -0.5 * beta * (y + model(y,t))\n",
        "        #print(c.shape)\n",
        "        c = jnp.squeeze(c, axis=0)\n",
        "        return c\n",
        "\n",
        "    term = dfx.ODETerm(drift)\n",
        "    solver = dfx.Tsit5()\n",
        "    t0 = 0\n",
        "    y1 = jr.normal(key, data_shape)\n",
        "    # reverse time, solve from t1 to t0\n",
        "    sol = dfx.diffeqsolve(term, solver, t1, t0, -dt0, y1)\n",
        "    return sol.ys[0]"
      ],
      "metadata": {
        "id": "P86wJHrRjSAf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Loop"
      ],
      "metadata": {
        "id": "m-BSAfb1Xxk0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Future main training loop"
      ],
      "metadata": {
        "id": "IsrCLvajo59T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(\n",
        "    # Model hyperparameters\n",
        "    input_size=28,\n",
        "    patch_size=4,\n",
        "    in_channels=1,\n",
        "    hidden_size=384,\n",
        "    depth=4,\n",
        "    n_head=6,\n",
        "    mlp_ratio=4.0,\n",
        "    frequency_embedding_size=256,\n",
        "    t1=10.0,\n",
        "    # Optimisation hyperparameters\n",
        "    num_steps=1_000_000,\n",
        "    lr=3e-4,\n",
        "    batch_size=256,\n",
        "    print_every=5_000,\n",
        "    # Sampling hyperparameters\n",
        "    dt0=0.1,\n",
        "    sample_size=10,\n",
        "    # Seed\n",
        "    seed=2023,\n",
        "):\n",
        "    key = jr.PRNGKey(seed)\n",
        "    model_key, train_key, loader_key, sample_key = jr.split(key, 4)\n",
        "    data = mnist()\n",
        "    data_mean = jnp.mean(data)\n",
        "    data_std = jnp.std(data)\n",
        "    data_max = jnp.max(data)\n",
        "    data_min = jnp.min(data)\n",
        "    #data_shape = data.shape[1:]\n",
        "    data = (data - data_mean) / data_std\n",
        "\n",
        "    model = DiT(\n",
        "        input_size,\n",
        "        patch_size,\n",
        "        in_channels,\n",
        "        hidden_size,\n",
        "        depth,\n",
        "        n_head,\n",
        "        mlp_ratio,\n",
        "        frequency_embedding_size,\n",
        "        key=model_key,\n",
        "    )\n",
        "    int_beta = lambda t: t  # Try experimenting with other options here!\n",
        "    weight = lambda t: 1 - jnp.exp(\n",
        "        -int_beta(t)\n",
        "    )  # Just chosen to upweight the region near t=0.\n",
        "\n",
        "    opt = optax.adabelief(lr)\n",
        "    # Optax will update the floating-point JAX arrays in the model.\n",
        "    opt_state = opt.init(eqx.filter(model, eqx.is_inexact_array))\n",
        "\n",
        "    total_value = 0\n",
        "    total_size = 0\n",
        "    for step, data in zip(\n",
        "        range(num_steps), dataloader(data, batch_size, key=loader_key)\n",
        "    ):\n",
        "        value, model, train_key, opt_state = make_step(\n",
        "            model, weight, int_beta, data, t1, train_key, opt_state, opt.update\n",
        "        )\n",
        "        total_value += value.item()\n",
        "        total_size += 1\n",
        "        if (step % print_every) == 0 or step == num_steps - 1:\n",
        "            print(f\"Step={step} Loss={total_value / total_size}\")\n",
        "            total_value = 0\n",
        "            total_size = 0\n",
        "\n",
        "    sample_key = jr.split(sample_key, sample_size**2)\n",
        "    sample_fn = ft.partial(single_sample_fn, model, int_beta, data_shape, dt0, t1)\n",
        "    sample = jax.vmap(sample_fn)(sample_key)\n",
        "    sample = data_mean + data_std * sample\n",
        "    sample = jnp.clip(sample, data_min, data_max)\n",
        "    sample = einops.rearrange(\n",
        "        sample, \"(n1 n2) 1 h w -> (n1 h) (n2 w)\", n1=sample_size, n2=sample_size\n",
        "    )\n",
        "    plt.imshow(sample, cmap=\"Greys\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "0fBuMTg5bqEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Temporary manual training loop"
      ],
      "metadata": {
        "id": "5hPwC8pOo-Qj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1=10.0\n",
        "# Optimisation hyperparameters\n",
        "num_steps=150_000\n",
        "lr=3e-4\n",
        "batch_size=256\n",
        "print_every=1_000"
      ],
      "metadata": {
        "id": "3DiMj1uH0l1D"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = mnist()\n",
        "data_mean = jnp.mean(data)\n",
        "data_std = jnp.std(data)\n",
        "data_max = jnp.max(data)\n",
        "data_min = jnp.min(data)\n",
        "data_shape = data.shape[1:]\n",
        "data = (data - data_mean) / data_std"
      ],
      "metadata": {
        "id": "5iqUlNfy0sOj",
        "outputId": "a4e6de95-63ed-4a31-b232-65ff2d815338",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded https://storage.googleapis.com/cvdf-datasets/mnist/train-images-idx3-ubyte.gz to /content/data/mnist/train-images-idx3-ubyte.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader_key, train_key, model_key, sample_key = jr.split(key, 4)"
      ],
      "metadata": {
        "id": "ZZtfxUuk1RqG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_uni = DiT(key = model_key)"
      ],
      "metadata": {
        "id": "5xC1QPWW0xmh"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########\n",
        "### b ####\n",
        "##########\n",
        "def zero_init(weight: jax.Array) -> jax.Array:\n",
        "  zw = jnp.zeros(weight.shape)\n",
        "  return zw\n",
        "\n",
        "def init_zero_weight(block, init_fn, key):\n",
        "  \n",
        "  get_weights = lambda block: [block.adaLN_modulation.layers[1].weight]\n",
        "  weights = get_weights(block)\n",
        "      \n",
        "  new_weights = [init_fn(weight) for weight in weights]\n",
        "  new_block = eqx.tree_at(get_weights, block, new_weights)\n",
        "\n",
        "\n",
        "  return new_block\n",
        "\n",
        "######################################\n",
        "def change_w(model, init_fn, key):\n",
        "  i=0\n",
        "  for _ in model.blocks:\n",
        "    model.blocks[i] = init_zero_weight(model.blocks[i], init_fn, key)\n",
        "\n",
        "    i+=1\n",
        "  #############  \n",
        "  get_weights = lambda m: [m.final_layer.adaLN_modulation.weight]\n",
        "  weights = get_weights(model)\n",
        "      \n",
        "  new_weights = [init_fn(weight) for weight in weights]\n",
        "  model = eqx.tree_at(get_weights, model, new_weights)\n",
        "########################\n",
        "  get_weights = lambda m: [m.final_layer.linear.weight]\n",
        "  weights = get_weights(model)\n",
        "      \n",
        "  new_weights = [init_fn(weight) for weight in weights]\n",
        "  model = eqx.tree_at(get_weights, model, new_weights)\n",
        "\n",
        "  return model\n",
        "\n",
        "model = change_w(model_uni, zero_init, key)"
      ],
      "metadata": {
        "id": "rV5rnr7H_mGI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int_beta = lambda t: t  # Try experimenting with other options here!\n",
        "weight = lambda t: 1 - jnp.exp(-int_beta(t))  "
      ],
      "metadata": {
        "id": "sfqWMuv_01gV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = optax.adabelief(lr)\n",
        "# Optax will update the floating-point JAX arrays in the model.\n",
        "opt_state = opt.init(eqx.filter(model, eqx.is_inexact_array))"
      ],
      "metadata": {
        "id": "0gN_Ft5J05yh"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import dump, load\n",
        "lossdict = {}"
      ],
      "metadata": {
        "id": "Ql-c0yhHlop_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_value = 0\n",
        "total_size = 0\n",
        "for step, data in zip(range(num_steps), dataloader(data, batch_size, key=loader_key)): \n",
        "    value, model, train_key, opt_state = make_step(model, weight, int_beta, data, t1, train_key, opt_state, opt.update)\n",
        "    total_value += value.item()\n",
        "    total_size += 1\n",
        "    if (step % print_every) == 0 or step == num_steps - 1:\n",
        "        print(f\"Step={step} Loss={total_value / total_size}\")\n",
        "        lossdict[step] = (total_value / total_size)\n",
        "        total_value = 0\n",
        "        total_size = 0"
      ],
      "metadata": {
        "id": "HR_WBH2ABNSb",
        "outputId": "34c6a49b-17b5-41ab-b26c-92d9d7b5312f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step=0 Loss=0.9997076988220215\n",
            "Step=1000 Loss=0.04003048910014331\n",
            "Step=2000 Loss=0.024938757399097084\n",
            "Step=3000 Loss=0.02398608314990997\n",
            "Step=4000 Loss=0.023197293616831302\n",
            "Step=5000 Loss=0.020029677521437406\n",
            "Step=6000 Loss=0.01684019384626299\n",
            "Step=7000 Loss=0.016042727760970592\n",
            "Step=8000 Loss=0.01559606163110584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save model**"
      ],
      "metadata": {
        "id": "WrfT_WIepFAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eqx.tree_serialise_leaves(\"DiT_cifar_hq.eqx\", model)\n",
        "shutil.copy('/content/DiT_cifar_hq.eqx','/content/gdrive/MyDrive/Colab_Notebooks')"
      ],
      "metadata": {
        "id": "6P4YFNU9niOD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e59a9baa-8d00-464f-c518-bcf193c2f5b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/Colab_Notebooks/DiT_cifar.eqx'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save losses**"
      ],
      "metadata": {
        "id": "YJ7W2k4Ho4_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./DiT_cifar_hq_losses.pkl', 'wb') as file:\n",
        "    dump(lossdict, file)\n",
        "\n",
        "import shutil\n",
        "shutil.copy('./DiT_cifar_hq_losses.pkl','/content/gdrive/MyDrive/Colab_Notebooks')"
      ],
      "metadata": {
        "id": "uvEnTENqomoY",
        "outputId": "c691e5ea-4cc1-4ed7-c74c-c678f832324d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/Colab_Notebooks/DiT_cifar_losses.pkl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sampling"
      ],
      "metadata": {
        "id": "ECNuSDaYgde2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_size = 8\n",
        "dt0 = 0.01"
      ],
      "metadata": {
        "id": "qBbPr-o6gxB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_key = jr.split(sample_key, sample_size**2)\n",
        "sample_fn = ft.partial(single_sample_fn, model, int_beta, data_shape, dt0, t1)\n",
        "sample = jax.vmap(sample_fn)(sample_key)\n",
        "sample = data_mean + data_std * sample\n",
        "sample = jnp.clip(sample, data_min, data_max)\n",
        "sample1 = sample[:, 0, :, :]\n",
        "sample2 = sample[:, 1, :, :]\n",
        "sample3 = sample[:, 2, :, :]\n",
        "   \n",
        "sample1 = einops.rearrange(sample1, \"(n1 n2) h w -> (n1 h) (n2 w) \", n1=sample_size, n2=sample_size)\n",
        "sample2 = einops.rearrange(sample2, \"(n1 n2) h w -> (n1 h) (n2 w) \", n1=sample_size, n2=sample_size)\n",
        "sample3 = einops.rearrange(sample3, \"(n1 n2) h w -> (n1 h) (n2 w) \", n1=sample_size, n2=sample_size)\n",
        "\n",
        "sample1 = sample1[None,:,:]\n",
        "sample2 = sample2[None,:,:]\n",
        "sample3 = sample3[None,:,:]\n",
        "    \n",
        "newsamp = jnp.concatenate([sample1, sample2, sample3])\n",
        "sample = einops.rearrange(newsamp, \"c h w -> h w c\")\n",
        "sample = jnp.array(sample, dtype=int)\n",
        "    \n",
        "    \n",
        "plt.imshow(sample)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "     "
      ],
      "metadata": {
        "id": "sas4H60VgWfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss curve**"
      ],
      "metadata": {
        "id": "vp4OHDOUkXkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test = load(open('./test_to_delete.pkl', 'rb'))\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "myList = lossdict.items()\n",
        "myList = sorted(myList) \n",
        "x, y = zip(*myList) \n",
        "\n",
        "plt.plot(x, y)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZdFVwID9kZxK",
        "outputId": "601473da-b17a-4b29-dd81-2f6607993707",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = lossdict.copy()"
      ],
      "metadata": {
        "id": "uQnK3vN2ktZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del a[0]"
      ],
      "metadata": {
        "id": "J62C4B7kk6jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test = load(open('./test_to_delete.pkl', 'rb'))\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "myList = a.items()\n",
        "myList = sorted(myList) \n",
        "x, y = zip(*myList) \n",
        "\n",
        "plt.plot(x, y)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FgbbYTZmk-_9",
        "outputId": "8086ecf9-0c17-4444-a93f-e6978eca7264",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Model**"
      ],
      "metadata": {
        "id": "IHuXyEDuo-uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = eqx.tree_deserialise_leaves('/content/gdrive/MyDrive/Colab_Notebooks/DiT_mnist.eqx', model)"
      ],
      "metadata": {
        "id": "xPqaiGVaZ5mQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}