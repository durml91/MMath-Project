{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vkxG8UA55CDs",
        "boKbD65w2odj",
        "XYdPvNIg2q6C",
        "aH_B8CT82uLR",
        "YuPSPusZ2v3N",
        "5C5kiQ_k2x7F",
        "udhjg0J-9pK0",
        "gV_U-JJrL-jC",
        "7wfr3bbCSZkk"
      ],
      "authorship_tag": "ABX9TyPIS0A6tZBgMIG+ixlyfgcK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/durml91/MMath-Project/blob/duo-branch/Image_Diffusion_(working)/DiT%20Diffusion/DiT-V2-CIFAR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**DiT implementation**"
      ],
      "metadata": {
        "id": "YJW-hYHrRghA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports and Installs"
      ],
      "metadata": {
        "id": "CwbREoSGRkg-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Need to install new version of Jax for package compatibility"
      ],
      "metadata": {
        "id": "9JBPitYdRoFm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TB7c1s9yAoVp"
      },
      "outputs": [],
      "source": [
        "!pip install jaxlib==0.4.2+cuda11.cudnn82 -f  https://storage.googleapis.com/jax-releases/jax_cuda_releases.html # [cuda]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install packages"
      ],
      "metadata": {
        "id": "53kc_s37RsQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffrax\n",
        "!pip install equinox\n",
        "!pip install einops\n",
        "!pip install optax"
      ],
      "metadata": {
        "id": "ZAhw7yT6AvfB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5420b393-23e3-4908-b892-dbb2ea61fc71"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting diffrax\n",
            "  Downloading diffrax-0.3.1-py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.4/140.4 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jax>=0.4.3\n",
            "  Downloading jax-0.4.4.tar.gz (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting equinox>=0.10.0\n",
            "  Downloading equinox-0.10.1-py3-none-any.whl (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.7/108.7 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jaxtyping>=0.2.12\n",
            "  Downloading jaxtyping-0.2.13-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from jax>=0.4.3->diffrax) (1.22.4)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.8/dist-packages (from jax>=0.4.3->diffrax) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.8/dist-packages (from jax>=0.4.3->diffrax) (1.7.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.8/dist-packages (from jaxtyping>=0.2.12->equinox>=0.10.0->diffrax) (4.5.0)\n",
            "Collecting typeguard>=2.13.3\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Building wheels for collected packages: jax\n",
            "  Building wheel for jax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jax: filename=jax-0.4.4-py3-none-any.whl size=1403844 sha256=2612b8ceb8b28ba0afde42c8f9e09662d9745eb4b6d8eed8220991c90c4855f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/cd/9b/750eb95db5b18b776ae59f55ae22b91a01e3703f3fb07eaa13\n",
            "Successfully built jax\n",
            "Installing collected packages: typeguard, jaxtyping, jax, equinox, diffrax\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 2.7.1\n",
            "    Uninstalling typeguard-2.7.1:\n",
            "      Successfully uninstalled typeguard-2.7.1\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.3.25\n",
            "    Uninstalling jax-0.3.25:\n",
            "      Successfully uninstalled jax-0.3.25\n",
            "Successfully installed diffrax-0.3.1 equinox-0.10.1 jax-0.4.4 jaxtyping-0.2.13 typeguard-2.13.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: equinox in /usr/local/lib/python3.8/dist-packages (0.10.1)\n",
            "Requirement already satisfied: jaxtyping>=0.2.12 in /usr/local/lib/python3.8/dist-packages (from equinox) (0.2.13)\n",
            "Requirement already satisfied: jax>=0.4.3 in /usr/local/lib/python3.8/dist-packages (from equinox) (0.4.4)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.8/dist-packages (from jax>=0.4.3->equinox) (1.7.3)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.8/dist-packages (from jax>=0.4.3->equinox) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from jax>=0.4.3->equinox) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.8/dist-packages (from jaxtyping>=0.2.12->equinox) (4.5.0)\n",
            "Requirement already satisfied: typeguard>=2.13.3 in /usr/local/lib/python3.8/dist-packages (from jaxtyping>=0.2.12->equinox) (2.13.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optax\n",
            "  Downloading optax-0.1.4-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.9/154.9 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from optax) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.8/dist-packages (from optax) (4.5.0)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.8/dist-packages (from optax) (0.4.2+cuda11.cudnn82)\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.8/dist-packages (from optax) (0.4.4)\n",
            "Collecting chex>=0.1.5\n",
            "  Downloading chex-0.1.6-py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.9/87.9 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from optax) (1.22.4)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.8/dist-packages (from chex>=0.1.5->optax) (0.1.8)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from chex>=0.1.5->optax) (0.12.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.8/dist-packages (from jax>=0.1.55->optax) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.8/dist-packages (from jax>=0.1.55->optax) (1.7.3)\n",
            "Installing collected packages: chex, optax\n",
            "Successfully installed chex-0.1.6 optax-0.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "DGZx1OUJRuUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import array\n",
        "import functools as ft\n",
        "import gzip\n",
        "import os\n",
        "import struct\n",
        "import urllib.request\n",
        "\n",
        "import diffrax as dfx  # https://github.com/patrick-kidger/diffrax\n",
        "import einops  # https://github.com/arogozhnikov/einops\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.random as jr\n",
        "import matplotlib.pyplot as plt\n",
        "import optax  # https://github.com/deepmind/optax\n",
        "\n",
        "import equinox as eqx"
      ],
      "metadata": {
        "id": "E1AYxrBfAxC6"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate rng key**"
      ],
      "metadata": {
        "id": "1Bw9Y9YTRwKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "key = jr.PRNGKey(2023)"
      ],
      "metadata": {
        "id": "7CDF6Fp0CL4J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4940ba1-79cd-457a-c5a1-6a98d4a35cb0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.lib.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup for saving model parameters - only run once!"
      ],
      "metadata": {
        "id": "o-FpEm9rR4Iv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFbT8W33BUPS",
        "outputId": "498228f9-046a-449c-81f9-91a794ac58bd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data loader and data shuffler"
      ],
      "metadata": {
        "id": "RiTiRLb7XjXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mnist():\n",
        "    filename = \"train-images-idx3-ubyte.gz\"\n",
        "    url_dir = \"https://storage.googleapis.com/cvdf-datasets/mnist\"\n",
        "    target_dir = os.getcwd() + \"/data/mnist\"\n",
        "    url = f\"{url_dir}/{filename}\"\n",
        "    target = f\"{target_dir}/{filename}\"\n",
        "\n",
        "    if not os.path.exists(target):\n",
        "        os.makedirs(target_dir, exist_ok=True)\n",
        "        urllib.request.urlretrieve(url, target)\n",
        "        print(f\"Downloaded {url} to {target}\")\n",
        "\n",
        "    with gzip.open(target, \"rb\") as fh:\n",
        "        _, batch, rows, cols = struct.unpack(\">IIII\", fh.read(16))\n",
        "        shape = (batch, 1, rows, cols)\n",
        "        return jnp.array(array.array(\"B\", fh.read()), dtype=jnp.uint8).reshape(shape)\n",
        "\n",
        "def cifar():\n",
        "  from tensorflow.keras.datasets import cifar10\n",
        "  (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "  set1 = jnp.array(x_train)\n",
        "  set2 = jnp.array(x_test)\n",
        "\n",
        "  data = jnp.concatenate((set1, set2))\n",
        "\n",
        "  data_reag = einops.rearrange(data, \"n h w c -> n c h w\")\n",
        "  return data_reag\n",
        "\n",
        "\n",
        "def dataloader(data, batch_size, *, key):\n",
        "    dataset_size = data.shape[0]\n",
        "    indices = jnp.arange(dataset_size)\n",
        "    while True:\n",
        "        perm = jr.permutation(key, indices)\n",
        "        (key,) = jr.split(key, 1)\n",
        "        start = 0\n",
        "        end = batch_size\n",
        "        while end < dataset_size:\n",
        "            batch_perm = perm[start:end]\n",
        "            yield data[batch_perm]\n",
        "            start = end\n",
        "            end = start + batch_size"
      ],
      "metadata": {
        "id": "Rgx0ctSJXlT5"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DiT Model"
      ],
      "metadata": {
        "id": "MxSYycHl2mpq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Utility functions**"
      ],
      "metadata": {
        "id": "toAYtcuUWfh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@eqx.filter_jit\n",
        "def modulate(x, shift, scale):\n",
        "    scale = jnp.expand_dims(scale, axis=0) \n",
        "    shift = jnp.expand_dims(shift, axis=0)  \n",
        "    c = (1 + scale) + shift\n",
        "    return x * c"
      ],
      "metadata": {
        "id": "UrDibia_WiyI"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@eqx.filter_jit\n",
        "def get_2d_sincos_pos_embed(n_embd, grid_size):\n",
        "\n",
        "    grid_h = jnp.arange(grid_size, dtype=float)\n",
        "    grid_w = jnp.arange(grid_size, dtype=float)\n",
        "    grid = jnp.meshgrid(grid_w, grid_h)\n",
        "    grid = jnp.stack(grid, axis=0)\n",
        "\n",
        "    #grid = einops.rearrange(grid, \" 2 d f -> 2 1 d f\")\n",
        "    grid = jnp.reshape(grid, (2, 1, grid_size, grid_size))\n",
        "    pos_embed = get_2d_sincos_pos_embed_from_grid(n_embd, grid)\n",
        "    return pos_embed\n",
        "\n",
        "\n",
        "##################################################################################\n",
        "\n",
        "@eqx.filter_jit\n",
        "def get_2d_sincos_pos_embed_from_grid(n_embd, grid):\n",
        "    assert n_embd % 2 == 0\n",
        "\n",
        "\n",
        "    emb_h = get_1d_sincos_pos_embed_from_grid(n_embd // 2, grid[0]) # (H*W, D/2)\n",
        "    emb_w = get_1d_sincos_pos_embed_from_grid(n_embd // 2, grid[1]) # (H*W, D/2)\n",
        "\n",
        "    emb = jnp.concatenate([emb_h, emb_w], axis=1)  #(H*W, D)\n",
        "    return emb\n",
        "\n",
        "\n",
        "##################################################################################\n",
        "\n",
        "@eqx.filter_jit\n",
        "def get_1d_sincos_pos_embed_from_grid(n_embd, pos):\n",
        "    assert n_embd % 2 == 0\n",
        "    omega = jnp.arange(n_embd // 2, dtype=float)\n",
        "    omega /= n_embd / 2\n",
        "    omega = 1. / 10000*omega #(D/2)\n",
        "\n",
        "    pos = jnp.array(pos)\n",
        "    #print(pos.shape)\n",
        "    #pos = einops.rearrange(pos, \"a -> a 0\")\n",
        "    out = jnp.outer(pos, omega)\n",
        "\n",
        "    emb_sin = jnp.sin(out)\n",
        "    emb_cos = jnp.cos(out)\n",
        "\n",
        "    emb = jnp.concatenate([emb_sin, emb_cos], axis=1)\n",
        "    return emb"
      ],
      "metadata": {
        "id": "EkoixIOpWs0g"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NN modules**"
      ],
      "metadata": {
        "id": "gnBO4_x7WcSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#############################################\n",
        "##############                ###############\n",
        "##############    DiT model   ###############\n",
        "##############                ###############\n",
        "#############################################\n",
        "\n",
        "\"\"\"Diffusion models meet Transformers!\"\"\"\n",
        "\n",
        "\n",
        "###########   Time embedding    #############\n",
        "\n",
        "\n",
        "\n",
        "###### Define silu activation ######\n",
        "\n",
        "from typing import Callable\n",
        "\n",
        "class Lambda1(eqx.Module):\n",
        "    fn: Callable\n",
        "    \n",
        "    def __call__(self, x, *, key=None):\n",
        "        return self.fn(x)\n",
        "\n",
        "###### Time embedding ######\n",
        "\n",
        "class TimeStepEmbedder(eqx.Module):\n",
        "    mlp: eqx.nn.Sequential\n",
        "    frequency_embedding_size: int\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_size,\n",
        "        frequency_embedding_size,   #set as 256\n",
        "        key\n",
        "    ):\n",
        "        l1key, l2key = jr.split(key, 2)\n",
        "        self.mlp = eqx.nn.Sequential([\n",
        "            eqx.nn.Linear(frequency_embedding_size, hidden_size, key=l1key),\n",
        "            Lambda1(jax.nn.silu),\n",
        "            eqx.nn.Linear(hidden_size, hidden_size, key=l2key)\n",
        "        ])\n",
        "        self.frequency_embedding_size = frequency_embedding_size\n",
        "\n",
        "    def __call__(self, t, max_period=10000):\n",
        "        dim = self.frequency_embedding_size\n",
        "        half = dim // 2\n",
        "        freqs = jnp.exp(\n",
        "            -jnp.log(max_period) * jnp.arange(0, half, dtype=float) / half\n",
        "        )\n",
        "        args = t[:, None].astype(float) * freqs[None]\n",
        "        embedding = jnp.concatenate([jnp.cos(args), jnp.sin(args)], axis=-1)\n",
        "        if dim % 2:\n",
        "            embedding = jnp.concatenate([embedding, jnp.zeros_like(embedding[:, :1])], axis=-1)\n",
        "        t_freq = embedding\n",
        "        t_emb = jax.vmap(self.mlp)(t_freq)\n",
        "        return t_emb\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##########   Multi-Head Attention   #########\n",
        "\n",
        "\n",
        "class MultiAtt(eqx.Module):\n",
        "    c_attn: eqx.nn.Linear\n",
        "    c_proj: eqx.nn.Linear\n",
        "    n_head: int\n",
        "    mha: eqx.nn.MultiheadAttention\n",
        "\n",
        "    def __init__(self, n_embd, n_head, key):\n",
        "        assert n_embd % n_head ==0\n",
        "        atkey, prkey, mhakey = jr.split(key, 3)\n",
        "        self.c_attn = eqx.nn.Linear(n_embd, 3 * n_embd, key=atkey)\n",
        "        self.c_proj = eqx.nn.Linear(n_embd, n_embd, key=prkey)\n",
        "        self.n_head = n_head\n",
        "        self.mha = eqx.nn.MultiheadAttention(n_head, n_embd, key=mhakey)\n",
        "\n",
        "    def __call__(self, x, mask=None):\n",
        "        B, T, C = x.shape\n",
        "        qkv = jax.vmap(jax.vmap(self.c_attn))(x)\n",
        "        q, k, v = jnp.array_split(qkv, 3, axis=-1)\n",
        "        values = jax.vmap(self.mha)(q, k, v)\n",
        "        out = jax.vmap(jax.vmap(self.c_proj))(values)\n",
        "        return out\n",
        "\n",
        "\n",
        "##############    DiT Block     ##############\n",
        "\n",
        "\n",
        "class DitBlock(eqx.Module):\n",
        "    norm1: eqx.nn.LayerNorm\n",
        "    norm2: eqx.nn.LayerNorm\n",
        "    attn: eqx.Module\n",
        "    Mlp: eqx.nn.MLP\n",
        "    adaLN_modulation: eqx.nn.Sequential\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_size,\n",
        "        n_head,\n",
        "        mlp_ratio,   # = 4.0\n",
        "        key,\n",
        "    ):\n",
        "        mkey, adakey = jr.split(key, 2)\n",
        "        self.norm1 = eqx.nn.LayerNorm(hidden_size, eps = 1e-06, elementwise_affine=False)\n",
        "        self.attn = MultiAtt(hidden_size, n_head=n_head, key=key)\n",
        "        self.norm2 = eqx.nn.LayerNorm(hidden_size, eps = 1e-06, elementwise_affine=False)\n",
        "        mlp_hidden_size = int(hidden_size * mlp_ratio)\n",
        "        self.Mlp = eqx.nn.MLP(hidden_size, hidden_size, mlp_hidden_size, 1, key=mkey)\n",
        "        self.adaLN_modulation = eqx.nn.Sequential([\n",
        "            Lambda1(jax.nn.silu),\n",
        "            eqx.nn.Linear(hidden_size, 6 * hidden_size, key=adakey)\n",
        "        ])\n",
        "\n",
        "    def __call__(self, x, c):\n",
        "        temp = jax.vmap(self.adaLN_modulation)(c)\n",
        "        shift_msa, scale_msa, gate_msa, shift_mlp, scale_mlp, gate_mlp = jnp.array_split(temp, 6, axis=1)\n",
        "        gate_msa = jnp.expand_dims(gate_msa, axis=0)\n",
        "        a = jax.vmap(self.norm1)(x)\n",
        "        tem = modulate(a, shift_msa, scale_msa)\n",
        "        x = x + gate_msa * self.attn(tem)\n",
        "        gate_mlp = jnp.expand_dims(gate_mlp, axis=0)\n",
        "        b = jax.vmap(self.norm2)(x)\n",
        "        tems = modulate(self.norm2(x), shift_mlp, scale_mlp)     \n",
        "        x = x + gate_mlp * jax.vmap(jax.vmap(self.Mlp))(tems)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#################   Final Layer   ################\n",
        "\n",
        "\n",
        "\n",
        "class FinalLayer(eqx.Module):\n",
        "    norm_final: eqx.nn.LayerNorm\n",
        "    linear: eqx.nn.Linear\n",
        "    adaLN_modulation: eqx.nn.Linear\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_size,\n",
        "        patch_size,\n",
        "        out_channels,\n",
        "        key\n",
        "    ):\n",
        "        lkey, adakey = jr.split(key, 2)\n",
        "        self.norm_final = eqx.nn.LayerNorm(hidden_size, eps=1e-6, elementwise_affine=False)\n",
        "        self.linear = eqx.nn.Linear(hidden_size, patch_size * patch_size * out_channels, key=lkey)\n",
        "        self.adaLN_modulation = eqx.nn.Linear(hidden_size, 2 * hidden_size, key=adakey)\n",
        "\n",
        "    def __call__(self, x, c):\n",
        "        c = jax.nn.silu(c)\n",
        "        temp = jax.vmap(self.adaLN_modulation)(c)\n",
        "        shift, scale = jnp.array_split(temp, 2, axis=1)\n",
        "        x = modulate(self.norm_final(x), shift, scale)\n",
        "        x = jax.vmap(jax.vmap(self.linear))(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "###########   Patch embedding   ##############\n",
        "\n",
        "class PatchEmbed(eqx.Module):\n",
        "    num_patches:int\n",
        "    proj: eqx.nn.Conv2d\n",
        "    patch_size: int\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        img_size,\n",
        "        patch_size,\n",
        "        in_chans,\n",
        "        n_embd,\n",
        "        key\n",
        "    ):\n",
        "        patkey, _ = jr.split(key,2)\n",
        "        self.patch_size = patch_size\n",
        "        dg = img_size // self.patch_size\n",
        "        self.num_patches = dg ** 2\n",
        "        self.proj = eqx.nn.Conv2d(in_chans, n_embd, self.patch_size, self.patch_size, key=patkey)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        x = jnp.array(x, dtype=float)\n",
        "        x = jax.vmap(self.proj)(x)\n",
        "        x = einops.rearrange(x, \"B C H W -> B (H W) C\")\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "###########   Parameter module    ##########\n",
        "\n",
        "class Params(eqx.Module):\n",
        "    param: jnp.ndarray\n",
        "\n",
        "    def __init__(self, num_patches, hidden_size):\n",
        "        self.param = jnp.zeros((1, num_patches, hidden_size), dtype = float)\n",
        "\n",
        "    def __call__(self):\n",
        "        return self.param\n",
        "\n",
        "\n",
        "##########    DiT   ##########\n",
        "\n",
        "\n",
        "class DiT(eqx.Module):\n",
        "    in_channels: int\n",
        "    out_channels: int\n",
        "    patch_size: int\n",
        "    n_head: int\n",
        "\n",
        "    x_embedder: eqx.Module\n",
        "    t_embedder: eqx.Module\n",
        "    pos_embed: eqx.Module\n",
        "    blocks: list\n",
        "    final_layer: eqx.Module\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size=32,\n",
        "        patch_size=4,\n",
        "        in_channels=3,\n",
        "        hidden_size=384,\n",
        "        depth=4,\n",
        "        n_head=6,\n",
        "        mlp_ratio=4.0,\n",
        "        frequency_embedding_size=256,\n",
        "        *,\n",
        "        key=key,\n",
        "        \n",
        "    ):\n",
        "        xkey, tkey, flkey, *dbkeys = jr.split(key, 3 + depth)\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = in_channels\n",
        "        self.patch_size = patch_size\n",
        "        self.n_head = n_head\n",
        "        self.x_embedder = PatchEmbed(input_size, patch_size, in_channels, hidden_size, key=xkey)\n",
        "        self.t_embedder = TimeStepEmbedder(hidden_size, frequency_embedding_size, key=tkey)\n",
        "        num_patches = self.x_embedder.num_patches\n",
        "        self.pos_embed = Params(num_patches, hidden_size)\n",
        "        self.blocks = [\n",
        "            DitBlock(\n",
        "                hidden_size, n_head, mlp_ratio, key = key\n",
        "            )\n",
        "            for dbkey in dbkeys                                   #_ in range(depth)           #*bkeys = jr.split(key, num_blocks)\n",
        "        ]\n",
        "        self.final_layer = FinalLayer(hidden_size, patch_size, self.out_channels, key=flkey)\n",
        "\n",
        "        pos_embed = get_2d_sincos_pos_embed(self.pos_embed().shape[-1], int(self.x_embedder.num_patches ** 0.5))\n",
        "        pos_embed = jnp.array(pos_embed, dtype=float)\n",
        "        self.pos_embed = jnp.expand_dims(pos_embed, axis=0)\n",
        "    \n",
        "    def unpatchify(self, x):\n",
        "        \"\"\"\n",
        "        x: (N, T, patch_size ** 2 * C)\n",
        "        imgs: (N, H, W, C)\n",
        "        \"\"\"\n",
        "        c = self.out_channels      \n",
        "        p = self.x_embedder.patch_size \n",
        "        h = w = int(x.shape[1] ** 0.5)    \n",
        "        x = jnp.reshape(x, (x.shape[0], h, w, p, p, c))\n",
        "        x = einops.rearrange(x, \"n h w p q c->n c h p w q\")\n",
        "        imgs = jnp.reshape(x, (x.shape[0], c, h * p, h * p))\n",
        "        return imgs\n",
        "    \n",
        "    def __call__(self, x, t):\n",
        "        #pos_embed = get_2d_sincos_pos_embed(self.pos_embed().shape[-1], int(self.x_embedder.num_patches ** 0.5))\n",
        "        \n",
        "        \n",
        "        \"\"\"\n",
        "        x: (N, C, H, W)\n",
        "        t: (N, )\n",
        "        \"\"\"\n",
        "        \n",
        "        t = jnp.array([t], dtype=int)\n",
        "        x = self.x_embedder(x) + self.pos_embed  # (N, T, D), where T = H * W / patch_size ** 2\n",
        "        t = self.t_embedder(t)   # (N, D)\n",
        "        for block in self.blocks:\n",
        "            x = block(x,t)    # (N, T, D)\n",
        "        x = self.final_layer(x, t)     # (N, T, patch_size ** 2 * out_channels) - N is the batch_size, T is the number of patches, \n",
        "        x = self.unpatchify(x)        # (N, out_channels, H, W)\n",
        "        x = jnp.squeeze(x, axis=0)\n",
        "        return x"
      ],
      "metadata": {
        "id": "rLBy2RgjSNc_"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Debugging functions"
      ],
      "metadata": {
        "id": "bxL33vh_yc7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = DiT()"
      ],
      "metadata": {
        "id": "lpe7zwvuSjyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test"
      ],
      "metadata": {
        "id": "F9lt_YfeUxk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = mnist()"
      ],
      "metadata": {
        "id": "thzcy2UYSayZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "569fc530-95e1-409c-bf30-7fc5e0f30b65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded https://storage.googleapis.com/cvdf-datasets/mnist/train-images-idx3-ubyte.gz to /content/data/mnist/train-images-idx3-ubyte.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eF9e4o-VShOm",
        "outputId": "3507788b-4b1c-4c08-c203-27900f7eabf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 1, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eg = data[0]\n",
        "eg = eg[None,:,:,:]"
      ],
      "metadata": {
        "id": "JbF3Bm69U0GN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eg.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PHJrvR1YJz1",
        "outputId": "bd0316f3-d846-4164-c732-ea61c79b4990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = 2"
      ],
      "metadata": {
        "id": "gr80hL8tU7Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(eg, t).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOItbatMU_wZ",
        "outputId": "20d19806-ef76-4fde-a8b9-d6955273faf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss functions"
      ],
      "metadata": {
        "id": "rDm2oF452jQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def single_loss_fn(model, weight, int_beta, data, t, key):\n",
        "    mean = data * jnp.exp(-0.5 * int_beta(t))\n",
        "    var = jnp.maximum(1 - jnp.exp(-int_beta(t)), 1e-5)\n",
        "    std = jnp.sqrt(var)\n",
        "    noise = jr.normal(key, data.shape)\n",
        "    y = mean + std * noise\n",
        "    y = jnp.expand_dims(y, axis=0)\n",
        "    pred = model(y,t)\n",
        "    return weight(t) * jnp.mean((pred + noise / std) ** 2)\n",
        "\n",
        "\n",
        "def batch_loss_fn(model, weight, int_beta, data, t1, key):\n",
        "    batch_size = data.shape[0]\n",
        "    tkey, losskey = jr.split(key)\n",
        "    losskey = jr.split(losskey, batch_size)\n",
        "    # Low-discrepancy sampling over t to reduce variance\n",
        "    t = jr.uniform(tkey, (batch_size,), minval=0, maxval=t1 / batch_size)\n",
        "    t = t + (t1 / batch_size) * jnp.arange(batch_size)\n",
        "    loss_fn = ft.partial(single_loss_fn, model, weight, int_beta)\n",
        "    loss_fn = jax.vmap(loss_fn)\n",
        "    return jnp.mean(loss_fn(data, t, losskey))"
      ],
      "metadata": {
        "id": "Xf-iL2jpBEB2"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Update function"
      ],
      "metadata": {
        "id": "kUh2huWlXtxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@eqx.filter_jit\n",
        "def make_step(model, weight, int_beta, data, t1, key, opt_state, opt_update):\n",
        "    loss_fn = eqx.filter_value_and_grad(batch_loss_fn)\n",
        "    loss, grads = loss_fn(model, weight, int_beta, data, t1, key)\n",
        "    updates, opt_state = opt_update(grads, opt_state)\n",
        "    model = eqx.apply_updates(model, updates)\n",
        "    key = jr.split(key, 1)[0]\n",
        "    return loss, model, key, opt_state"
      ],
      "metadata": {
        "id": "J0sVh0_nBKOZ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sampler"
      ],
      "metadata": {
        "id": "RRsIwypJjORC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@eqx.filter_jit\n",
        "def single_sample_fn(model, int_beta, data_shape, dt0, t1, key):\n",
        "    def drift(t, y, args):\n",
        "        _, beta = jax.jvp(int_beta, (t,), (jnp.ones_like(t),))\n",
        "        y = jnp.expand_dims(y, axis=0)\n",
        "        c = -0.5 * beta * (y + model(y,t))\n",
        "        #print(c.shape)\n",
        "        c = jnp.squeeze(c, axis=0)\n",
        "        return c\n",
        "\n",
        "    term = dfx.ODETerm(drift)\n",
        "    solver = dfx.Tsit5()\n",
        "    t0 = 0\n",
        "    y1 = jr.normal(key, data_shape)\n",
        "    # reverse time, solve from t1 to t0\n",
        "    sol = dfx.diffeqsolve(term, solver, t1, t0, -dt0, y1)\n",
        "    return sol.ys[0]"
      ],
      "metadata": {
        "id": "P86wJHrRjSAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Loop"
      ],
      "metadata": {
        "id": "m-BSAfb1Xxk0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Future main training loop"
      ],
      "metadata": {
        "id": "IsrCLvajo59T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(\n",
        "    # Model hyperparameters\n",
        "    input_size=28,\n",
        "    patch_size=4,\n",
        "    in_channels=1,\n",
        "    hidden_size=384,\n",
        "    depth=4,\n",
        "    n_head=6,\n",
        "    mlp_ratio=4.0,\n",
        "    frequency_embedding_size=256,\n",
        "    t1=10.0,\n",
        "    # Optimisation hyperparameters\n",
        "    num_steps=1_000_000,\n",
        "    lr=3e-4,\n",
        "    batch_size=256,\n",
        "    print_every=5_000,\n",
        "    # Sampling hyperparameters\n",
        "    dt0=0.1,\n",
        "    sample_size=10,\n",
        "    # Seed\n",
        "    seed=2023,\n",
        "):\n",
        "    key = jr.PRNGKey(seed)\n",
        "    model_key, train_key, loader_key, sample_key = jr.split(key, 4)\n",
        "    data = mnist()\n",
        "    data_mean = jnp.mean(data)\n",
        "    data_std = jnp.std(data)\n",
        "    data_max = jnp.max(data)\n",
        "    data_min = jnp.min(data)\n",
        "    #data_shape = data.shape[1:]\n",
        "    data = (data - data_mean) / data_std\n",
        "\n",
        "    model = DiT(\n",
        "        input_size,\n",
        "        patch_size,\n",
        "        in_channels,\n",
        "        hidden_size,\n",
        "        depth,\n",
        "        n_head,\n",
        "        mlp_ratio,\n",
        "        frequency_embedding_size,\n",
        "        key=model_key,\n",
        "    )\n",
        "    int_beta = lambda t: t  # Try experimenting with other options here!\n",
        "    weight = lambda t: 1 - jnp.exp(\n",
        "        -int_beta(t)\n",
        "    )  # Just chosen to upweight the region near t=0.\n",
        "\n",
        "    opt = optax.adabelief(lr)\n",
        "    # Optax will update the floating-point JAX arrays in the model.\n",
        "    opt_state = opt.init(eqx.filter(model, eqx.is_inexact_array))\n",
        "\n",
        "    total_value = 0\n",
        "    total_size = 0\n",
        "    for step, data in zip(\n",
        "        range(num_steps), dataloader(data, batch_size, key=loader_key)\n",
        "    ):\n",
        "        value, model, train_key, opt_state = make_step(\n",
        "            model, weight, int_beta, data, t1, train_key, opt_state, opt.update\n",
        "        )\n",
        "        total_value += value.item()\n",
        "        total_size += 1\n",
        "        if (step % print_every) == 0 or step == num_steps - 1:\n",
        "            print(f\"Step={step} Loss={total_value / total_size}\")\n",
        "            total_value = 0\n",
        "            total_size = 0\n",
        "\n",
        "    sample_key = jr.split(sample_key, sample_size**2)\n",
        "    sample_fn = ft.partial(single_sample_fn, model, int_beta, data_shape, dt0, t1)\n",
        "    sample = jax.vmap(sample_fn)(sample_key)\n",
        "    sample = data_mean + data_std * sample\n",
        "    sample = jnp.clip(sample, data_min, data_max)\n",
        "    sample = einops.rearrange(\n",
        "        sample, \"(n1 n2) 1 h w -> (n1 h) (n2 w)\", n1=sample_size, n2=sample_size\n",
        "    )\n",
        "    plt.imshow(sample, cmap=\"Greys\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "0fBuMTg5bqEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Temporary manual training loop"
      ],
      "metadata": {
        "id": "5hPwC8pOo-Qj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1=10.0\n",
        "# Optimisation hyperparameters\n",
        "num_steps=500_000\n",
        "lr=3e-4\n",
        "batch_size=256\n",
        "print_every=1_000"
      ],
      "metadata": {
        "id": "3DiMj1uH0l1D"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = cifar()\n",
        "data_mean = jnp.mean(data)\n",
        "data_std = jnp.std(data)\n",
        "data_max = jnp.max(data)\n",
        "data_min = jnp.min(data)\n",
        "data_shape = data.shape[1:]\n",
        "data = (data - data_mean) / data_std"
      ],
      "metadata": {
        "id": "5iqUlNfy0sOj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65ba44c1-be74-43ce-9841-879159e74e3e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 6s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader_key, train_key, model_key, sample_key = jr.split(key, 4)"
      ],
      "metadata": {
        "id": "ZZtfxUuk1RqG"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DiT(key = model_key)"
      ],
      "metadata": {
        "id": "5xC1QPWW0xmh"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int_beta = lambda t: t  # Try experimenting with other options here!\n",
        "weight = lambda t: 1 - jnp.exp(-int_beta(t))  "
      ],
      "metadata": {
        "id": "sfqWMuv_01gV"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = optax.adabelief(lr)\n",
        "# Optax will update the floating-point JAX arrays in the model.\n",
        "opt_state = opt.init(eqx.filter(model, eqx.is_inexact_array))"
      ],
      "metadata": {
        "id": "0gN_Ft5J05yh"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import dump, load\n",
        "lossdict = {}"
      ],
      "metadata": {
        "id": "Ql-c0yhHlop_"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_value = 0\n",
        "total_size = 0\n",
        "for step, data in zip(range(num_steps), dataloader(data, batch_size, key=loader_key)): \n",
        "    value, model, train_key, opt_state = make_step(model, weight, int_beta, data, t1, train_key, opt_state, opt.update)\n",
        "    total_value += value.item()\n",
        "    total_size += 1\n",
        "    if (step % print_every) == 0 or step == num_steps - 1:\n",
        "        print(f\"Step={step} Loss={total_value / total_size}\")\n",
        "        lossdict[step] = (total_value / total_size)\n",
        "        total_value = 0\n",
        "        total_size = 0"
      ],
      "metadata": {
        "id": "HR_WBH2ABNSb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "8abc1422-2cfb-416e-b3bb-1e2f5204a3e4"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step=0 Loss=1.279609203338623\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-52a5177d05ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtotal_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloader_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_beta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtotal_value\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtotal_size\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/equinox/jit.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fun_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fun_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/equinox/jit.py\u001b[0m in \u001b[0;36m_fun_wrapper\u001b[0;34m(self, is_lower, args, kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mdynamic_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcombine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdynamic_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/equinox/module.py\u001b[0m in \u001b[0;36m_tree_unflatten\u001b[0;34m(cls, aux, dynamic_field_values)\u001b[0m\n\u001b[1;32m    283\u001b[0m         )\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_tree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_field_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save model**"
      ],
      "metadata": {
        "id": "WrfT_WIepFAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eqx.tree_serialise_leaves(\"DiT_mnist.eqx\", model)\n",
        "shutil.copy('/content/DiT_mnist.eqx','/content/gdrive/MyDrive/Colab_Notebooks')"
      ],
      "metadata": {
        "id": "6P4YFNU9niOD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "7929d54c-d603-495f-9970-7632d40c4fac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/Colab_Notebooks/DiT_mnist.eqx'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save losses**"
      ],
      "metadata": {
        "id": "YJ7W2k4Ho4_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./DiT_mnist_losses.pkl', 'wb') as file:\n",
        "    dump(lossdict, file)\n",
        "\n",
        "import shutil\n",
        "shutil.copy('./DiT_mnist_losses.pkl','/content/gdrive/MyDrive/Colab_Notebooks')"
      ],
      "metadata": {
        "id": "uvEnTENqomoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sampling"
      ],
      "metadata": {
        "id": "ECNuSDaYgde2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_size = 8\n",
        "dt0 = 0.025"
      ],
      "metadata": {
        "id": "qBbPr-o6gxB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_key = jr.split(sample_key, sample_size**2)\n",
        "sample_fn = ft.partial(single_sample_fn, model, int_beta, data_shape, dt0, t1)\n",
        "sample = jax.vmap(sample_fn)(sample_key)\n",
        "sample = data_mean + data_std * sample\n",
        "sample = jnp.clip(sample, data_min, data_max)\n",
        "sample = einops.rearrange(sample, \"(n1 n2) 1 h w -> (n1 h) (n2 w)\", n1=sample_size, n2=sample_size)\n",
        "plt.imshow(sample, cmap=\"Greys\")\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sas4H60VgWfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experimentation"
      ],
      "metadata": {
        "id": "cfVgX06PY36V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Model**"
      ],
      "metadata": {
        "id": "IHuXyEDuo-uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = eqx.tree_deserialise_leaves('/content/gdrive/MyDrive/Colab_Notebooks/DiT_mnist.eqx', model)"
      ],
      "metadata": {
        "id": "xPqaiGVaZ5mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### pkl test - works!"
      ],
      "metadata": {
        "id": "lB--prZrhJso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import dump, load"
      ],
      "metadata": {
        "id": "hynuGBa8Zazo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dic = {1000:1.02, 2000:0.9, 3000:0.72, 4000:0.54, 5000:0.34}"
      ],
      "metadata": {
        "id": "0XlBX73HY640"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./test_to_delete.pkl', 'wb') as file:\n",
        "    dump(dic, file)"
      ],
      "metadata": {
        "id": "zAleD-ITZaTq"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.copy('./test_to_delete.pkl','/content/gdrive/MyDrive/Colab_Notebooks')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "DxrGANNNa-6B",
        "outputId": "055fb077-1fdb-4bb6-b36d-72ac5d67ba53"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/Colab_Notebooks/test_to_delete.pkl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " test = load(open('./test_to_delete.pkl', 'rb'))"
      ],
      "metadata": {
        "id": "o2yJuCGhdrn1"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36sBYldBd1zl",
        "outputId": "d27e1653-2b9c-447a-8093-94e53f891201"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1000: 1.02, 2000: 0.9, 3000: 0.72, 4000: 0.54, 5000: 0.34}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test[6000]=0.054"
      ],
      "metadata": {
        "id": "NPrq8OxUjhe1"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ot84oMOcjp7A",
        "outputId": "09c992c8-cd9f-43c5-cb76-d263b22371fd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1000: 1.02, 2000: 0.9, 3000: 0.72, 4000: 0.54, 5000: 0.34, 6000: 0.054}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(test.items())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yZNoJehj50S",
        "outputId": "b322dc57-9fc4-4ea5-8bde-cd16ce650ec4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1000, 1.02),\n",
              " (2000, 0.9),\n",
              " (3000, 0.72),\n",
              " (4000, 0.54),\n",
              " (5000, 0.34),\n",
              " (6000, 0.054)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test Graph**"
      ],
      "metadata": {
        "id": "e_O0si_zhwMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pylab as plt\n",
        "myList = test.items()\n",
        "myList = sorted(myList) \n",
        "x, y = zip(*myList) \n",
        "\n",
        "plt.plot(x, y)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "GniIWsvRhtsP",
        "outputId": "78bc4d6c-0859-4bbb-fb63-bad7c3feb979"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eFqjjL6Vk9fp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}