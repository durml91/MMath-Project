{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3Z4poACTVrxa57MM7SpW/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/durml91/MMath-Project/blob/duo-branch/Diffusion_RL/Offline_RL_Diffusion_run_through.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Non exectutable run through of the offline RL + diffusion paper which can be found here: https://github.com/Zhendong-Wang/Diffusion-Policies-for-Offline-RL\n",
        "\n"
      ],
      "metadata": {
        "id": "hJ_UMOXkcN04"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main stuff"
      ],
      "metadata": {
        "id": "pdGUiQMpcYh8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we proceed to go through the main parts of the agent starting with the diffusion policy below."
      ],
      "metadata": {
        "id": "KX4kFVitcap8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The policy is technically a BC policy that essentially infers the policy from a given dataset. This is DDPMs diffusion and is all pretty straightforward to that end. Given python adopts the oop paradigm, *args and **kwargs is common when defining classes; really good article here: https://realpython.com/python-kwargs-and-args/ - quick summary are that they allow for general unpacking of iterable objects, specifically * on any iterable and ** specifically dictionaries - these are arguments of functions that allow you to be more \"general\" with how you define your inputs - this basically all to do about unpacking, and allows you to use python functions with more fluidity (rather than having to specifically define a function with a list for example, that means every time you call the function, you must specifically have to input that object, although you may want to use that function more generally for all kinds of objects) - good thing to adopt!"
      ],
      "metadata": {
        "id": "2P-xry4UchKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "from agents.helpers import (cosine_beta_schedule,\n",
        "                            linear_beta_schedule,\n",
        "                            vp_beta_schedule,\n",
        "                            extract,\n",
        "                            Losses)\n",
        "from utils.utils import Progress, Silent\n",
        "\n",
        "\n",
        "\n",
        "class Diffusion(nn.Module):     \n",
        "    def __init__(self, state_dim, action_dim, model, max_action, beta_schedule='linear', n_timesteps=100, loss_type='l2', clip_denoised=True, predict_epsilon=True):\n",
        "        super(Diffusion, self).__init__() #for some reason we are accessing a parent class for diffusion - not sure why\n",
        "\n",
        "\n",
        "        #these are all the input parameters, that are come from the D4RL dataset - i.e. this is the data\n",
        "        self.state_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "        self.max_action = max_action\n",
        "        self.model = model\n",
        "\n",
        "        #there are three beta functions here - not really that important\n",
        "        if beta_schedule == 'linear':\n",
        "            betas = linear_beta_schedule(n_timesteps)\n",
        "        elif beta_schedule == 'cosine':\n",
        "            betas = cosine_beta_schedule(n_timesteps)\n",
        "        elif beta_schedule == 'vp':\n",
        "            betas = vp_beta_schedule(n_timesteps)\n",
        "\n",
        "        \n",
        "        #work out your parameters for the Gaussian transition kernel.\n",
        "        alphas = 1. - betas\n",
        "        alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "        alphas_cumprod_prev = torch.cat([torch.ones(1), alphas_cumprod[:-1]])\n",
        "\n",
        "        \n",
        "        #again we intiliase some inputs like the number of timesteps - don't really know what the other two are really doing?\n",
        "        self.n_timesteps = int(n_timesteps)\n",
        "        self.clip_denoised = clip_denoised\n",
        "        self.predict_epsilon = predict_epsilon\n",
        "\n",
        "\n",
        "        #we register the parameters we calculated above\n",
        "        self.register_buffer('betas', betas)\n",
        "        self.register_buffer('alphas_cumprod', alphas_cumprod)\n",
        "        self.register_buffer('alphas_cumprod_prev', alphas_cumprod_prev)\n",
        "\n",
        "        # calculations for diffusion q(x_t | x_{t-1}) and others\n",
        "        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))\n",
        "        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))\n",
        "        self.register_buffer('log_one_minus_alphas_cumprod', torch.log(1. - alphas_cumprod))\n",
        "        self.register_buffer('sqrt_recip_alphas_cumprod', torch.sqrt(1. / alphas_cumprod))\n",
        "        self.register_buffer('sqrt_recipm1_alphas_cumprod', torch.sqrt(1. / alphas_cumprod - 1))\n",
        "\n",
        "        # calculations for posterior q(x_{t-1} | x_t, x_0)\n",
        "        posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
        "        self.register_buffer('posterior_variance', posterior_variance)\n",
        "\n",
        "        ## log calculation clipped because the posterior variance\n",
        "        ## is 0 at the beginning of the diffusion chain\n",
        "        self.register_buffer('posterior_log_variance_clipped', # clamp is equivalent to jnp.clip in JAX\n",
        "                             torch.log(torch.clamp(posterior_variance, min=1e-20)))\n",
        "        self.register_buffer('posterior_mean_coef1',\n",
        "                             betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod))\n",
        "        self.register_buffer('posterior_mean_coef2',\n",
        "                             (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod))\n",
        "\n",
        "        self.loss_fn = Losses[loss_type]()\n",
        "\n",
        "    # ------------------------------------------ sampling ------------------------------------------#\n",
        "  \n",
        "    def predict_start_from_noise(self, x_t, t, noise):\n",
        "        '''\n",
        "            if self.predict_epsilon, model output is (scaled) noise;\n",
        "            otherwise, model predicts x0 directly\n",
        "        '''\n",
        "        if self.predict_epsilon:\n",
        "            return (\n",
        "                    extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -\n",
        "                    extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise\n",
        "            )\n",
        "        else:\n",
        "            return noise\n",
        "\n",
        "    def q_posterior(self, x_start, x_t, t):\n",
        "        posterior_mean = (\n",
        "                extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +\n",
        "                extract(self.posterior_mean_coef2, t, x_t.shape) * x_t\n",
        "        )\n",
        "        posterior_variance = extract(self.posterior_variance, t, x_t.shape)\n",
        "        posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)\n",
        "        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n",
        "\n",
        "    def p_mean_variance(self, x, t, s):\n",
        "        x_recon = self.predict_start_from_noise(x, t=t, noise=self.model(x, t, s))\n",
        "\n",
        "        if self.clip_denoised:\n",
        "            x_recon.clamp_(-self.max_action, self.max_action)\n",
        "        else:\n",
        "            assert RuntimeError()\n",
        "\n",
        "        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(x_start=x_recon, x_t=x, t=t)\n",
        "        return model_mean, posterior_variance, posterior_log_variance\n",
        "\n",
        "    # @torch.no_grad()\n",
        "    def p_sample(self, x, t, s):\n",
        "        b, *_, device = *x.shape, x.device\n",
        "        model_mean, _, model_log_variance = self.p_mean_variance(x=x, t=t, s=s)\n",
        "        noise = torch.randn_like(x)\n",
        "        # no noise when t == 0\n",
        "        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))\n",
        "        return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise\n",
        "\n",
        "    # @torch.no_grad()\n",
        "    def p_sample_loop(self, state, shape, verbose=False, return_diffusion=False):\n",
        "        device = self.betas.device\n",
        "\n",
        "        batch_size = shape[0]\n",
        "        x = torch.randn(shape, device=device)\n",
        "\n",
        "        if return_diffusion: diffusion = [x]\n",
        "\n",
        "        progress = Progress(self.n_timesteps) if verbose else Silent()\n",
        "        for i in reversed(range(0, self.n_timesteps)):\n",
        "            timesteps = torch.full((batch_size,), i, device=device, dtype=torch.long)\n",
        "            x = self.p_sample(x, timesteps, state)\n",
        "\n",
        "            progress.update({'t': i})\n",
        "\n",
        "            if return_diffusion: diffusion.append(x)\n",
        "\n",
        "        progress.close()\n",
        "\n",
        "        if return_diffusion:\n",
        "            return x, torch.stack(diffusion, dim=1)\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "    # @torch.no_grad()\n",
        "    def sample(self, state, *args, **kwargs):\n",
        "        batch_size = state.shape[0]\n",
        "        shape = (batch_size, self.action_dim)\n",
        "        action = self.p_sample_loop(state, shape, *args, **kwargs)\n",
        "        return action.clamp_(-self.max_action, self.max_action)\n",
        "\n",
        "    # ------------------------------------------ training ------------------------------------------#\n",
        "\n",
        "    #\n",
        "    def q_sample(self, x_start, t, noise=None):\n",
        "        if noise is None:\n",
        "            noise = torch.randn_like(x_start)\n",
        "\n",
        "        sample = (\n",
        "                extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +\n",
        "                extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise\n",
        "        )\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def p_losses(self, x_start, state, t, weights=1.0):\n",
        "        noise = torch.randn_like(x_start)\n",
        "\n",
        "        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)\n",
        "\n",
        "        x_recon = self.model(x_noisy, t, state)\n",
        "\n",
        "        assert noise.shape == x_recon.shape\n",
        "\n",
        "        if self.predict_epsilon:\n",
        "            loss = self.loss_fn(x_recon, noise, weights)\n",
        "        else:\n",
        "            loss = self.loss_fn(x_recon, x_start, weights)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def loss(self, x, state, weights=1.0):\n",
        "        batch_size = len(x)\n",
        "        t = torch.randint(0, self.n_timesteps, (batch_size,), device=x.device).long()\n",
        "        return self.p_losses(x, state, t, weights)\n",
        "\n",
        "    def forward(self, state, *args, **kwargs):\n",
        "        return self.sample(state, *args, **kwargs)"
      ],
      "metadata": {
        "id": "o-4u35JCcuVL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}